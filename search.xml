<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux+Windows10双系统安装及基本配置]]></title>
    <url>%2F2019%2F11%2F27%2FLinux-Windows10%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言在Windows10系统上搭建完深度学习环境用于无人驾驶中的目标检测后，想在Linux系统上再尝试一下。故先需要装一个双系统，本文介绍如何安装双系统以及装完系统后的输入法和英伟达显卡驱动配置。 正文1.安装双系统主要参考Windows + Linux 双系统的安装这篇文章。按照文章所述步骤来，基本没有问题。主要分为如下几个步骤： 1.1 U盘启动盘的制作（将Ubuntu系统ISO 格式镜像文件借助Rufus工具加载进U盘，从而将U盘制作成启动盘） 1.2 分配磁盘空间（ 留出磁盘空间用于安装ubuntu 系统） 2.1 分区 目录 建议大小 格式 描述 / 150G-200G ext4 根目录 /tmp 5G左右 ext4 系统的临时文件，一般系统重启不会被保存。 /boot 1G左右 ext4 系统引导起始位置，建议：应该大于400MB或1GB Linux的内核及引导系统程序所需要的文件，比如 vmlinuz initrd.img文件都位于这个目录中。在一般情况下，GRUB 或 LILO 系统引导管理器也位于这个目录；启动撞在文件存放位置，如kernels，initrd，grub。 /home 尽量大些 ext4 用户工作目录；个人配置文件，如个人环境变量等；所有账号分配一个工作目录。 swap 物理内存的两倍 交换空间 交换空间：交换分区相当于Windows中的“虚拟内存”，如果内存低的话（1-4G），物理内存的两倍，高点的话（8-16G）要么等于物理内存，要么物理内存+2g左右 2.2 安装（分区完成准备安装） 3.1 启动项修改（安装好双系统后你的电脑开机时可能默认还是选择 windows 启动，可以通过EasyBCD工具对启动顺序进行修改） 2.安装搜狗输入法Linux自带的输入法不是太好用，而且正常在Windows系统里面使用的是搜狗输入法，并且搜狗输入法发行了Linux版本，故没有任何理由不在Linux系统上安装一个 搜狗输入法。 1）下载搜狗输入法（注意32位和64位） https://pinyin.sogou.com/linux/?r=pinyin 2）按键Ctr+Alt+T打开终端，输入以下命令切换到下载文件夹: 1cd ~/下载/ 3) 查看是否下载完成 1ls 4) 安装输入法 1sudo dpkg -i sogoupinyin_2.3.1.0112_amd64.deb 1234567891011121314#会报错dpkg: 处理软件包 sogoupinyin (--install)时出错： 依赖关系问题 - 仍未被配置正在处理用于 mime-support (3.60ubuntu1) 的触发器 ...正在处理用于 libglib2.0-0:i386 (2.56.1-2ubuntu1) 的触发器 ...覆盖文件 /usr/glib-2.0/schemas/50_sogoupinyin.gschema.override 中指定的方案 org.gnome.settings-daemon.plugins.xsettings 中没有键 Gtk/IMModule；忽略对此键的覆盖。正在处理用于 libglib2.0-0:amd64 (2.56.1-2ubuntu1) 的触发器 ...覆盖文件 /usr/glib-2.0/schemas/50_sogoupinyin.gschema.override 中指定的方案 org.gnome.settings-daemon.plugins.xsettings 中没有键 Gtk/IMModule；忽略对此键的覆盖。正在处理用于 gnome-menus (3.13.3-11ubuntu1) 的触发器 ...正在处理用于 desktop-file-utils (0.23-1ubuntu3) 的触发器 ...正在处理用于 shared-mime-info (1.9-2) 的触发器 ...正在处理用于 hicolor-icon-theme (0.17-2) 的触发器 ...在处理时有错误发生： sogoupinyin 5）解决依赖问题 1sudo apt-get -f install 6)再次安装 1sudo dpkg -i sogoupinyin_2.3.1.0112_amd64.deb 7)重启 1reboot 8)从桌面右上角系统设置里面点击“语言支持”，从跳出来的第一个对话框选择“安装”按钮，然后就开始安装，期间会提示输入密码。 当安装结束以后，在“语言支持“窗口把系统键盘输入方式从ibus切换为fcitx。 9）重启 1reboot 10）点击右上角键盘标志，选择“配置当前输入法”，然后点击“+”，添加合适的输入法，我这里最终选择的是“键盘-英语（美国）+搜狗拼音“。这样，就和在Windows10上使用搜狗输入法时一样，按”Shift键“就可以切换中文和英文输入法。 3.安装英伟达显卡驱动一方便是由于配置深度学习环境的需要，另一方面是由于没有显卡驱动的话，整个界面的分辨率有限，影响观感。 1）安装环境 操作系统：Ubuntu 16.04 LTS 显卡：NVIDIA GeForce RTX 2060 2) 打开NVIDIA驱动官网，选择最新的一个驱动程序，下载 注意： 版本选择Linux，不要下载Windows10 64bits 3）禁用nouveau驱动 打开文件 1sudo vim /etc/modprobe.d/blacklist.conf 在文件末尾添加以下几行命令 blacklist nouveau blacklist rivafb blacklist rivatv blacklist nvidiafb options nouveau modeset=04) 更新Linux系统内核 1sudo update-initramfs -u 5) 重启并检查nouveau驱动是否成功被禁 12rebootlsmod | grep nouveau 重启电脑后，打开终端输入命令以查看nouveau驱动是否成功被禁，命令无返回则是成功禁用。 6) 安装驱动.run文件 12cd ~/下载/sudo sh NVIDIA-Linux-x86_64-440.36.run -no-x-check -no-nouveau-check -no-opengl-files 参数解释： –no-x-check：表示安装驱动时不检查X服务（图形接口服务），如果没有关闭图形界面则必须加上，否则反之。 –no-nouveau-check：表示安装驱动时不检查nouveau驱动，这也是非必需的，因为我们已经在前面步骤中禁用驱动。 –no-opengl-files：表示只安装驱动文件，不安装OpenGL文件。这个参数不可省略，否则会导致登陆界面死循环，英语一般称为”login loop”或者”stuck in login”。 8) 安装进行时的选项 选项 选择 The distribution-provided pre-install script failed! Are you sure you want to continue? Continue Unable to find a suitable destination to install 32-bit compatibility libraries. Your system may not be set up for 32-bit compatibility. 32-bit compatibility files will not be installed; if you wish to install them, re-run the installation and set a valid directory with the –compat32-libdir option. OK Would you like to run the nvidia-xconfigutility to automatically update your x configuration so that the NVIDIA x driver will be used when you restart x? Any pre-existing x confile will be backed up. Yes Your X configuration file has been successfully updated. Installation of the NVIDIA Accelerated Graphics Driver for Linux-x86_64 (version: 430.40) is now complete. OK 9)在命令行中输入 1nvidia-smi 如出现以下画面，即证明已正确安装一半。 10）重启电脑 1reboot 11) 接着在命令行中输入 1nvidia-settings 出现以下界面，代表显卡安装完全正确。 后文大环境搭建好了，下一步就准备搭建深度学习环境用于目标检测了。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>双系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读取天气信息，并通过QQ邮箱每天给好友定时发送]]></title>
    <url>%2F2019%2F10%2F27%2F%E8%AF%BB%E5%8F%96%E5%A4%A9%E6%B0%94%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%B9%B6%E9%80%9A%E8%BF%87QQ%E9%82%AE%E7%AE%B1%E6%AF%8F%E5%A4%A9%E7%BB%99%E5%A5%BD%E5%8F%8B%E5%AE%9A%E6%97%B6%E5%8F%91%E9%80%81%2F</url>
    <content type="text"><![CDATA[1.结果假设你的好友和你不在一个城市，他不怎么经常关注天气情况而你又想对他表示关心，那么这篇推送就非常适合你。先来看下结果吧，你的好友会根据你的设置每天在某一时间收到一封你发给他的邮件，邮件内容如下： 类似的根据不同的API接口，还可以每天定时发送一封关于金山词霸每日一句、睡前小故事的邮件等等。 2.前提第一条，你得有一个集成开发环境来运行程序，由于我使用的是Python语言，所以需要类似PyCharm或者Spyder的开发环境。 第二条，你需要看到我这篇文章，很明显这一条你已经做到了（手动滑稽）。 3.正文我对实现上述功能的理解大致可以总结为这么一句话：我要向谁通过什么接口在每天什么时间发送什么信息，并且得到什么适当的反馈，证明已经发送成功。所以程序大致可以分为以下几个步骤。 3.1 我你需要知道自己的QQ号，这个没什么问题吧。 3.2谁这里有人会困惑，我到底该发给谁呢，想什么呢，当然是发给你的好基友啊，不然还发给你喜欢的对象（手动滑稽） 3.3接口这里使用的是QQ邮箱的接口，有个比较重要的参数是QQ邮箱的授权码。为此，我们得先获取该授权码。 1）登录自己的QQ号，并进入QQ邮箱界面。 2）点击设置，然后在邮箱设置里面选择账户。 3）然后向下拖动，点击生成授权码，按照相应的提示做就可以了。 4）如果没有温馨提示一栏，就点击开启POP3/SMTP服务。 5)授权码是一串小写英文字符串。 3.4定时顾名思义，就是在每天的某一时刻发送邮件，只需要更改时间参数即可。 3.5信息这里的信息指得就是天气信息。这里有两点要注意： 1）你需要获得城市编号，这个可以通过中国天气网官网（http://www.weather.com.cn/），然后搜索城市名称获得。 2）替换掉参数。 3）需要获得具体关于天气的信息。打开中国天气网后，按F12即可进入开发者工具，然后找到对应的关键词。 4）程序参数来源。 5）在return部分，除了截图中的内容外，可以自由发挥，加一些俏皮的内容。 3.6反馈当我们想知道对方是否收到邮件时，除了问对方外，还可以自己做一些设置。 这里，我设置的是当程序运行时，会有start打印出来，当发送成功时，会打印发送完成。 4.改进由于本程序是在本地运行的，所以得一直使程序在运行状态才行。后面可以考虑将程序运行在云服务器上。]]></content>
      <categories>
        <category>小项目</category>
      </categories>
      <tags>
        <tag>天气</tag>
        <tag>QQ邮箱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo和GitHub免费搭建个人博客网站]]></title>
    <url>%2F2019%2F10%2F09%2F%E5%9F%BA%E4%BA%8EHexo%E5%92%8CGitHub%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[基于Hexo和GitHub免费搭建个人博客网站1.引言阮一峰大神说喜欢写博客的人，会经历三个阶段。 第一阶段，刚接触博客觉得很新鲜，试着选择一个免费空间来写。比如CSDN、博客园。 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。比如阿里云、腾讯云。 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。比如基于Hexo和GitHub免费搭建个人博客网站。 Github提供了Pages功能，只要将写好的Markdown文章提交到Github上托管，即可生成独立博客，而且提供几乎不限流量的存储空间，一切都是免费的。一旦搭建好，则只需要负责写文章就行了，不需要定期维护。 Hexo 是一个基于Node.js的静态博客框架。Hexo使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 之前介绍过写Markdown文章的神器Typora，今天就让我们来关注具体搭建个人博客网站。 本文是针对Windows10系统，其他诸如Mac系统还有Linux系统请参考百度相关内容。 2.Hexo的搭建步骤2.1 安装Git BashGit Bash用来管理你的Hexo博客文章，并将文章上传到GitHub平台的工具。 1）具体的安装过程就是一直点击next，直到出现install，点击install，安装完成后点击finish，然后在任意文件夹下右键打开Git Bsah Here输入命令git --version，查看有没有安装成功。 注意：右键点击Git Bash Here 如果出现下图，则说明安装路径中有中文（软件安装）。 2.2 安装Node.jsHexo是基于Node.js编写的，所以需要安装该软件。从官网下载，然后安装即可，直接选择LTS（长期支持版）版本的。 1）安装完成后，打开管理员命令行输入命令node -v以及npm -v，查看有没有安装成功。 2.3 安装Hexo1）创建一个文件夹Blog，然后进入该文件夹右键Git Bash Here打开。输入命令npm install -g hexo-cli，至此就安装完成了。 2）安装完成后，还需要初始化hexo，即执行如下命令： 12hexo initnpm install 3）新建完成后，在Blog文件夹下会出现许多新的文件，目录如下： node_modules：是依赖包 scaffolds：命令生成Markdown文章等的模板 source：用命令创建的各种Markdown文章 themes：主题文件夹，Hexo 会根据主题来生成静态页面。 _config.yml：站点配置文件，您可以在此配置大部分的参数。 db.json：source解析所得到的 package.json：项目所需模块项目的配置信息 4）输入如下命令，然后在浏览器中输入localhost:4000(本地查看)即可查看用hexo生成的博客了。 12hexo ghexo s 使用ctrl+c可以把服务关掉。 5）至此，Blog文件夹下会多出两个目录 .deploy_git public 注意：出现bash： npm： command not found错误。 网上试了各种办法，最后重启一下电脑就没有问题了。 3.Hexo关联到GitHub静态页面已经有了，我们还需要将其部署到GitHub上。一来我们搭建博客想要别人可以（以一个链接）访问到我们的博客，二来我们需要有个托管平台，这样我们就可以关注博客内容本身而不是麻烦的管理。 3.1 GitHub创建个人仓库1）首先注册一个GitHub账号 2）然后点击New，新建仓库 按照下图所示操作后，点击Create repository即创建成功。 3.2生成SSH添加到GitHub1）在git bash输入如下命令 12git config --global user.name "yourname"git config --global user.email "youremail" 这里的yourname输入你的GitHub用户名，youremail输入你GitHub的邮箱。这样GitHub才能知道你是不是对应它的账户。 2)然后创建SSH,一路回车 1ssh-keygen -t rsa -C "youremail" 这个时候它会告诉你已经生成了.ssh的文件夹。在你的电脑中找到这个文件夹后可以发现有两个文件（一般位于C盘）。 3)然后在GitHub的setting中，找到SSH keys的设置选项，点击New SSH key把id_rsa.pub里面的信息复制进去。 SSH，简单来讲，就是一个秘钥，其中，id_rsa是你这台电脑的私人秘钥，不能给别人看的，id_rsa.pub是公共秘钥，可以随便给别人看。把这个公钥放在GitHub上，这样当你链接GitHub自己的账户时，它就会根据公钥匹配你的私钥，当能够相互匹配时，才能够顺利的通过git上传你的文件到GitHub上。 3.3 将Hexo部署到GitHub1）用Notepad++打开站点配置文件 _config.yml。搜索关键词deploy。将YourgithubName对应的修改为你的GitHub用户名。 1234deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: master 2）这个时候需要先安装deploy-git ，也就是部署的命令,这样你才能用命令部署到GitHub。 1npm install hexo-deployer-git --save 3） 1hexo n bolgname 然后就会发现在Blog/source/_posts目录下出现一个名为blogname的Markdown文章，用Typora软件打开，文件最上方以 --- 分隔的区域，有用于指定个别文件的变量的Front-matter。我是用的个参数具体包括：title，categories，tags，date。 用Typora打开模板文件Blog/scaffolds/post.md文件，可以进行相应的设置。 4) 然后使用两个命令即可将你写好的文章（位于Blog/source/_posts文件夹下）部署到GitHub。 123hexo g # 生成静态文章hexo d # 部署文章hexo s # 可以先从本地（localhost:4000）预览效果，在部署文章到GitHub上 注意： 1）输入hexo d命令后需要你输入username和password。 得到下图就说明部署成功了，过一会儿就可以在http://yourname.github.io 这个网站看到你的博客了。 2）在上面第三步中提到Front-matter，其中除了我使用的几个参数外，还有其他参数。 3）另外，在上面第三步中提到Blog/scaffolds目录，其实该目录下一共有三个文件，刚刚只提到了post.md，还有另外两个文件。 其实这三个文件是对应三种不同的布局（layout）。 123451.hexo n [layout] &lt;tittle&gt; # 之前在创建文章时，layout默认是post，名为title的文章在Blog/source/_posts文件夹下2.hexo n draft &lt;tittle&gt; # draft是草稿的意思，名为title的文章在Blog/source/_drafts文件夹下，hexo s --draft # 草稿写好文章后，可以在本地开启预览hexo p draft &lt;tittle&gt; # 将名为title的文章发送到Blog/source/_posts文件夹下3.hexo new page board # 系统会自动在source文件夹下创建一个board文件夹，以及board文件夹中的index.md，这样你访问的board对应的链接就是http://xxx.xxx/board 4.Hexo的基本页面配置4.1 hexo基本配置用Notepad++打开站点配置文件 _config.yml，我们可以在 _config.yml 中修改大部分的配置。 1）网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 您的名字 language 网站使用的语言 timezone 网站时区，Hexo 默认使用您电脑的时区。 2）网址 参数 描述 默认值 url 网址 root 网站根目录 permalink 文章的永久链接格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 url：网站域名 permalink：分享某篇文章后在对方的网页中显示的域名。 3）其他设置默认就可以了，更多基本设置可以参考Hexo官网配置内容。 4.2 更换主题1）系统默认给的主题是landscape，并且在hexo官网还提供了270个主题，可以先预览选择一个主题。 比如我个人喜欢next主题，那么怎么应用该主题呢。 2）点击右上角从GitHub上面下载下来，然后再把整个文件夹放到Blog/themes目录下。 3）然后将Blog目录下_config.yml文件中的主题改为next。 4）进入Blog/themes/next目录下，里面也有一个配置文件_config.yml，这个配置文件是修改你整个主题的配置文件。 menu（菜单栏） 文件搜索关键词menu。 search(搜索框) 1npm install hexo-generator-searchdb --save # 安装插件 修改站点配置文件（位于Blog/_config.yml）中添加内容 12345search: path: search.xml field: post format: html limit: 10000 avatar（头像） 文件搜索关键词avatar。将准备好的头像放置在Blog/themes/next/source/images目录下。 social（社交） 文件搜索关键词social。 进度条 搜索关键词b2t，将图中两条均改为true。即可得到位于左侧栏的top按钮，可以实时显示阅读进度。 5.Hexo的高端页面配置（比较灵活）hexo添加各种功能，主要包括 搜索的SEO 阅读量统计 访问量统计 评论系统等 可以自由选择添加，具体的设置可以参考这篇文章。 6.其他本文是基于Node.js的静态博客框架Hexo，其他的博客各位如果感兴趣可以参考网络资源进行相应的博客搭建。下面列出了常见的静态博客。 6.1静态博客 jekyllrb.com（基于ruby） gohugo.org(基于go) vuepress.vuejs.org（基于vuejs） solo.b3log.org(基于java)]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶环境感知--基于深度学习的车道线检测]]></title>
    <url>%2F2019%2F09%2F17%2F%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5--%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[前言前面提到了使用基于霍夫变换的车道线检测，这种方法虽然操作简单，不需要对样本进行标注，但是相应的也有其局限性。 没有学习过程，对环境变化没有适应性 兴趣区域固定，且取决于摄像机、车辆相对于道路的位置 各种图像处理过程的参数、阈值等需要提前设定，调整不灵活 处理速度慢，4.5-6帧/秒，正常读取速度为30帧/秒 故本文介绍处理准确率更高，对环境适应性更好的基于深度学习的车道线检测。 正文1.数据集功能：用于标注，喂给设计好的模型进行训练。 1）从12个视频（包括一天不同时间、不同天气、不同交通状况和弯曲道路）中选取21054个图像 17.4%是夜晚清晰场景，16.4%是早上雨天场景，66.2%是下午阴天场景 26.5%是直线或者近乎直线道路，30.2%是混合或者略弯的道路，43.3%是相当弯曲的道路（道路还包括不同的区域，比如在修路段和十字路口） 2）滤去模糊和遮挡的图像，最终从中选取了14235个图像 3）在从10个中选取1个（视频相邻帧过于近似），最终含有1420个图像 4）从Udacity ‘s Advanced Lane Lines project取一些图，加上一些其它处理，最终有1978个实际图像 5）最终使用的图像：旋转处理后，扩展为6382个图像，水平翻转后，最终12764个图像 6）原始图像尺寸为80乘160乘3，对应的图片和标注结果如下图。 2.深度学习模型功能：根据标注的数据结合设计好的模型进行训练，一般训练会花费很多时间，所以为了方便实际工程使用会在训练后生成.h5文件（基于Keras框架）。 代码一：导入相关库123456789101112import numpy as npimport picklefrom sklearn.utils import shufflefrom sklearn.model_selection import train_test_split# 导入Keras的一些库及函数from keras.models import Sequentialfrom keras.layers import Activation, Dropout, UpSampling2Dfrom keras.layers import Conv2DTranspose, Conv2D, MaxPooling2Dfrom keras.layers.normalization import BatchNormalizationfrom keras.preprocessing.image import ImageDataGeneratorfrom keras import regularizers 代码二：数据预处理123456789101112131415161718192021# Load training imagestrain_images = pickle.load(open("full_CNN_train.p", "rb" ))# Load image labelslabels = pickle.load(open("full_CNN_labels.p", "rb" ))# Make into arrays as the neural network wants thesetrain_images = np.array(train_images)labels = np.array(labels)# 标准化标签 - 训练图像在神经网络的入口标准化labels = labels / 255# Shuffle images along with their labels, then split into training/validation setstrain_images, labels = shuffle(train_images, labels)# Test size may be 10% or 20%X_train, X_test, y_train, y_test = train_test_split(train_images, labels, test_size=0.1) print( 'X_train.shape: ' + str(X_train.shape))print( 'X_test.shape: ' + str(X_test.shape))print( 'Y_train.shape: ' + str(Y_train.shape))print( 'Y_test.shape: ' + str(Y_test.shape)) 注意： 1）在机器学习中，我们常常需要把训练好的模型存储起来，这样在进行决策时直接将模型读出，而不需要重新训练模型，这样就大大节约了时间。Python提供的pickle模块就很好地解决了这个问题，它可以序列化对象并保存到磁盘中，并在需要的时候读取出来，任何对象都可以执行序列化操作。 Pickle模块中最常用的函数为：pickle.load(file) 函数的功能：将file中的对象序列化读出。 2）train_test_split()是sklearn.model_selection中的分离器函数，用于将数组或矩阵划分为训练集和测试集，函数样式为：X_train, X_test, y_train, y_test = train_test_split(train_images, labels, test_size, random_state，shuffle) test_size：浮点数，在0 ~ 1之间，表示样本占比（test_size = 0.3，则样本数据中有30%的数据作为测试数据，记入X_test，其余70%数据记入X_train，同时适用于样本标签）；整数，表示样本数据中有多少数据记入X_test中，其余数据记入X_train random_state：随机数种子，种子不同，每次采的样本不一样；种子相同，采的样本不变（random_state不取，采样数据不同，但random_state等于某个值，采样数据相同，取0的时候也相同，这可以自己编程尝试下，不过想改变数值也可以设置random_state = int(time.time())） shuffle：洗牌模式，shuffle = False，不打乱样本数据顺序；shuffle = True，打乱样本数据顺序 3）打印： 1234X_train.shape: (11487, 80, 160, 3)X_test.shape: (1277, 80, 160, 3)Y_train.shape: (11487, 80, 160, 1)Y_test.shape: (1277, 80, 160, 1) 代码三：训练时的一些超参数12345# Batch size, epochs and pool size below are all paramaters to fiddle with for optimizationbatch_size = 128epochs = 10pool_size = (2, 2)input_shape = X_train.shape[1:] # (80, 160, 3) 代码四：深度学习模型1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677### 神经网络架构 ###model = Sequential()# Normalizes incoming inputs. First layer needs the input shape to workmodel.add(BatchNormalization(input_shape=input_shape))# Below layers were re-named for easier reading of model summary; this not necessary# Conv Layer 1model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))# Conv Layer 2model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))# Pooling 1model.add(MaxPooling2D(pool_size=pool_size))# Conv Layer 3model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))model.add(Dropout(0.2))# Conv Layer 4model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))model.add(Dropout(0.2))# Conv Layer 5model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))model.add(Dropout(0.2))# Pooling 2model.add(MaxPooling2D(pool_size=pool_size))# Conv Layer 6model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))model.add(Dropout(0.2))# Conv Layer 7model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))model.add(Dropout(0.2))# Pooling 3model.add(MaxPooling2D(pool_size=pool_size))# Upsample 1model.add(UpSampling2D(size=pool_size))# Deconv 1model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))model.add(Dropout(0.2))# Deconv 2model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))model.add(Dropout(0.2))# Upsample 2model.add(UpSampling2D(size=pool_size))# Deconv 3model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))model.add(Dropout(0.2))# Deconv 4model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))model.add(Dropout(0.2))# Deconv 5model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))model.add(Dropout(0.2))# Upsample 3model.add(UpSampling2D(size=pool_size))# Deconv 6model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))# Final layer - only including one channel so 1 filtermodel.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))### End of network ### 注意： 1）神经网络架构可视化 2）Keras 有两种不同的建模方式： Sequential models: 这种方法用于实现一些简单的模型。你只需要向一些存在的模型中添加层就行了。本程序采用的是该建模方式。 12from keras.models import Sequentialmodels=Sequential() Functional API: Keras的API是非常强大的，你可以利用这些API来构造更加复杂的模型，比如多输出模型，有向无环图等等。 1from keras.models import Model 代码五：训练模型12345678910111213141516171819# 使用ImageDataGenerator帮助模型使用少量数据datagen = ImageDataGenerator(channel_shift_range=0.2)#channel_shift_range：浮点数，随机通道偏移的幅度。datagen.fit(X_train)# 编译（指定优化器和损失函数）model.compile(optimizer='Adam', loss='mean_squared_error')# 利用批量生成器让模型对数据进行拟合model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,epochs=epochs, verbose=1, validation_data=(X_test, y_test))# 当训练完成时冻结层model.trainable = Falsemodel.compile(optimizer='Adam', loss='mean_squared_error')# 保存模型model.save('full_CNN_model.h5')# Show summary of modelmodel.summary() 注意： 1）ImageDataGenerator()是keras.preprocessing.image模块中的图片生成器，同时也可以在batch中对数据进行增强，扩充数据集大小，增强模型的泛化能力。比如进行旋转，变形，归一化等等。· 2）利用model.fit_generator让模型对数据进行拟合，它在数据生成上的效果和fit相同。 它的第一个参数应该是一个Python生成器，可以不停地生成输入和目标组成的批量，比如datagen.flow（按batch_size大小从x,y生成增强数据）。 因为数据是不断生成的，所以Keras模型要知道每一轮需要从生成器中抽取多少个样本。这是steps-per-epoch参数的作用：从生成器中抽取steps_per_epoch个批量后（即运行了steps_per_epoch次梯度下降），拟合过程将进入下一个轮次。本例中，每个批量包含128个样本，所以读取完所有11487个样本需要90个批量。 使用fit_generator时，你可以传人一个validation_data参数，其作用和在fit方法中类似。值得注意的是，这个参数可以是一个数据生成器，但也可以是Numpy数组组成的元组。如果validation_data传人一个生成器，那么这个生成器应该能够不停地生成验证数据批量，因此你还需要指定validation_steps参数，说明需要从验证生成器中抽取多少个批次用于评估。 3）在Keras中，冻结网络的方法是将其trainable的属性设为False。如果在编译之后修改了权重的trainable属性，那么应该重新编译模型，否则这些修改将被忽略。 3.车道线检测功能：将模型训练得到的.h5文件和待检测视频作为输入，得到车道线检测后的视频文件结果。 代码一：导入库123456789import numpy as npimport cv2from scipy.misc import imresizefrom moviepy.editor import VideoFileClip#from IPython.display import HTMLfrom keras.models import load_model# 载入预训练模型model = load_model('full_CNN_model.h5') 代码二：检测算法1234567891011121314151617181920212223242526272829303132333435363738394041# Class to average lanes withclass Lanes(): def __init__(self): self.recent_fit = [] # 包含所有的绘制好预测车道线的RGB图像 self.avg_fit = [] # def road_lines(image): """ 获取道路图像，调整图像大小，从模型中预测的车道将被绘制为绿色， 重新创建一个包含绘制车道线的RGB图像，并与原来的道路图像相融合。 """ # Get image ready for feeding into model small_img = imresize(image, (80, 160, 3)) small_img = np.array(small_img) small_img = small_img[None,:,:,:] #(1, 80, 160, 3) # Make prediction with neural network (非标准化) prediction = model.predict(small_img)[0] * 255 # Add lane prediction to list for averaging lanes.recent_fit.append(prediction) # Only using last five for average if len(lanes.recent_fit) &gt; 5: lanes.recent_fit = lanes.recent_fit[1:] # Calculate average detection lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]),axis = 0) # Generate fake R &amp; B color dimensions, stack with G blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8) lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks)) # 将图片尺寸调成和原始视频图像同样大小的尺寸 lane_image = imresize(lane_drawn, (1080,1920, 3)) # 将绘制的车道线和原始道路图像相融合 result = cv2.addWeighted(image, 1, lane_image, 1, 0) return result# 实例化Lanes类lanes = Lanes() 注意： 1）dstack 表示将数组在第三维进行堆叠（即第三层方括号），可将 arr 第三层括号里面的东西视为一个整体，即： 123456789101112131415161718arr1 = [[[块1], [块2], [块3]],[[块4], [块5], [块6]],[[块7], [块8], [块9]]]arr2 = [[[块11], [块12], [块13]],[[块14], [块15], [块16]],[[块17], [块18], [块19]]]# 然后 dstack((arr1, arr2)) 的结果如下：[[[块1 + 块11],[块2 + 块12],[块3 + 块13]][[块4 + 块14],[块5 + 块15],[块6 + 块16]][[块7 + 块17],[块8 + 块18],[块9 + 块19]]] 2）cv2.addWeighted( )函数说明 1cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) → dst dst = src1 * alpha + src2 * beta + gamma 其中： src1 – 第一张图片 alpha – 第一张图片的权重 src2 – 与第一张大小和通道数相同的图片 beta – 第二张图片的权重 dst – 输出，python中可以直接将dst放在前面作为输出 gamma – 加到每个总和上的标量，相当于调亮度 3）原视频图像的大小可以这样查看：右键-&gt;属性-&gt;详细信息-&gt;帧宽度、帧高度 代码三：检测视频流中的车道线并保存成另外的视频123456789101112# 输出视频vid_output = 'output_freeway_clip.mp4'# 输入视频#clip1 = VideoFileClip("project_video.mp4")clip1 = VideoFileClip("freeway_clip.mp4")# 将视频分帧并且对每一帧图像进行车道线检测 vid_clip = clip1.fl_image(road_lines)# 将检测好的视频帧图像再合并成视频 vid_clip.write_videofile(vid_output, audio=False) 4.原图与实际检测效果1）原图 2）实际检测]]></content>
      <categories>
        <category>无人驾驶环境感知</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>车道线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令及vim编辑器的使用]]></title>
    <url>%2F2019%2F09%2F16%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%A5%E5%8F%8Avim%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言本文提到的的命令都是在Linux终端下使用的，也就是所谓的黑窗口。正常打开Linux系统是有界面的，也可以通过鼠标像在Windows上操作那样进行点击图标，新建文件等操作。所以想使用终端得另外打开，Ctrl + Alt + T和Ctrl + D是两个常用的打开和关闭终端的快捷键方式。 1．Linux常用命令1.1 使用频率较高的命令1ifconfig #查看IP地址，可以利用该地址让Linux主机被远程控 12345678#通过sudo（“超级用户执行”）命令，你可以临时以root用户身份运行其他命令。这是大多数用户运行root权限命令的最佳方式，因为这样既不用维护root帐户，也不需要知道root用户密码。只要输入自己的用户密码，就能获得临时的root权限。chen@chen-virtual-machine:~$ sudo apt-get update #更新软件列表。[sudo] chen 的密码：xxx #正常输入密码的时候是不会显示的#其他类似的命令还有sudo apt-get install xxx #安装XXX软件。sudo apt-get upgrade #更新已安装软件。sudo apt-get remove xxx #删除XXX软件。 1234567##永久获得root用户身份chen@chen-virtual-machine:~$ su - #chen是用户名;注意':'后面'$';命令是‘SU -’密码： xxx #正常输入密码的时候是不会显示的root@chen-virtual-machine:~# #root是指此时已经获得了root权限；注意':'后面'#' 1.2 Linux文件与目录管理我们知道Linux的目录结构为树状结构，最顶级的目录为根目录 /。 上图是根目录下的一些目录，其中最常用的是home目录。 1.2.1目录和路径1）相对路径和绝对路径 绝对路径：路径的写法，一定由根目录 / 写起，例如： /home/chen/test1 这个目录。 123#以绝对路径进入test1目录root@chen-virtual-machine:~# cd /home/chen/test2/test1 root@chen-virtual-machine:/home/chen/test2/test1# 相对路径：路径的写法，不是由 根目录/ 写起，例如由/home/chen/test1 要到 /home/chen/test2 底下时，可以写成： cd ../test2 。 123root@chen-virtual-machine:/home/chen# cd test1 #首先进入test1目录root@chen-virtual-machine:/home/chen/test1# cd ../test2 #其次进入test2目录root@chen-virtual-machine:/home/chen/test2# 2）目录的相关操作cd：切换目录 123456789101112131415161.root@chen-virtual-machine:~# cd ~chenroot@chen-virtual-machine:/home/chen# #代表进入chen这个使用者的家目录，也就是/home/chenroot@chen-virtual-machine:/home/chen# lschen test1 模板 文档 桌面examples.desktop test2 视频 下载slambook 公共的 图片 音乐#列出目录下的文件2.root@chen-virtual-machine:/home/chen# cd ~3.root@chen-virtual-machine:/home/chen# cd#两个命令都表示回到自己家目录，也就是/root这个目录root@chen-virtual-machine:~# lschen1 Tom#列出目录下的文件4.cd ..表示进入当前目录的上一层目录5.cd - 表示进入当前目录的的前一个工作目录 pwd：显示当前目录cd 12345678root@chen-virtual-machine:/# cd /var/mailroot@chen-virtual-machine:/var/mail# pwd/var/mail#列出目前的工作目录root@chen-virtual-machine:/var/mail# pwd -P/var/spool/mail#/var/mail/是链接文件，链接到/var/spool/mail，加上-P的选项后，不会显示链接文件(快捷方式)的路径，而是显示正确的完整路径#P为大写 mkdir：建立一个新的目录 12345678root@chen-virtual-machine:/home/chen# mkdir test3#创建一名为test3的新目录root@chen-virtual-machine:/home/chen# mkdir test4/test1/test2mkdir: 无法创建目录"test4/test1/test2": 没有那个文件或目录#本来没有test4/test1这些目录，所以无法创建test2这个目录root@chen-virtual-machine:/home/chen# mkdir -p test4/test1/test2#加上-p的选项后，先创建test4/test1这些目录，然后再创建test2这个目录#p为小写 rmdir：删除一个空目录 12345678root@chen-virtual-machine:/home/chen# rmdir test3#删除一名为test3的目录root@chen-virtual-machine:/home/chen# rmdir test4rmdir: 删除 'test4' 失败: 目录非空root@chen-virtual-machine:/home/chen# rmdir -p test4/test1/test2#加上-p的选项后，可以直接删除test4目录下的所有空目录，非空目录删不掉root@chen-virtual-machine:/home/chen# rm -r test4#也可以使用rm -r 删除test4下的所有内容，可以非空 1.2.2 文件与目录管理1）ls1234567891011121314151617181920212223242526272829303132331.root@chen-virtual-machine:/home# cd chen2.root@chen-virtual-machine:/home/chen# cd ~chen3.root@chen-virtual-machine:/home/chen# lschen slambook test2 模板 图片 下载 桌面examples.desktop test1 公共的 视频 文档 音乐4.root@chen-virtual-machine:/home/chen# ls -d.#仅列出目录本身，而不是列出目录内的文件数据5.root@chen-virtual-machine:/home/chen# ls -l总用量 60drwxrwxr-x 2 chen chen 4096 9月 10 16:36 chen-rw-r--r-- 1 chen chen 8980 4月 20 15:05 examples.desktopdrwxrwxr-x 3 chen chen 4096 5月 23 12:52 slambookdrwxr-xr-x 2 root root 4096 9月 10 14:33 test1drwxr-xr-x 4 root root 4096 9月 10 14:39 test2drwxr-xr-x 2 chen chen 4096 4月 20 15:23 公共的drwxr-xr-x 2 chen chen 4096 4月 20 15:23 模板drwxr-xr-x 2 chen chen 4096 4月 20 15:23 视频drwxr-xr-x 2 chen chen 4096 4月 20 15:23 图片drwxr-xr-x 2 chen chen 4096 4月 20 15:23 文档drwxr-xr-x 2 chen chen 4096 4月 20 15:23 下载drwxr-xr-x 2 chen chen 4096 4月 20 15:23 音乐drwxr-xr-x 3 chen chen 4096 5月 23 10:11 桌面#详细信息显示，包含文件的属性与权限等数据6.root@chen-virtual-machine:/home/chen# ls -a. .cache .local test1 视频.. chen .mozilla test2 图片.apport-ignore.xml .config .profile .thunderbird 文档.bash_history examples.desktop slambook .viminfo 下载.bash_logout .gnupg .subversion 公共的 音乐.bashrc .ICEauthority .sudo_as_admin_successful 模板 桌面#全部的文件，连同隐藏文件（开头为.的文件）一起列出来 2）cp:复制文件或目录123456789101112131415161718192021221.root@chen-virtual-machine:/home/chen# cp /home/chen/test/a.py /home/chen/test1#将a.py文件拷贝到test1目录下2.root@chen-virtual-machine:/home/chen# cp -i /home/chen/test/a.py /home/chen/test1cp：是否覆盖'/home/chen/test1/a.py'？ yroot@chen-virtual-machine:/home/chen##加上-i选项后，则在覆盖前会询问使用者是否确定，可以按下n或y来二次确认3.root@chen-virtual-machine:/home/chen/test# cd ~chen/test1root@chen-virtual-machine:/home/chen/test1# cp /home/chen/test/b.py .#先进入想要将文件拷贝到的目录，然后再将其他目录的文件拷贝进来，注意最后的小点。root@chen-virtual-machine:/home/chen/test1# ls -l /home/chen/test/b.py b.py-rw-r--r-- 1 root root 0 9月 12 21:07 b.py-rw-r--r-- 1 root root 0 9月 12 21:06 /home/chen/test/b.py#这个时候原文件和拷贝文件的属性、权限可能会有差异。4.root@chen-virtual-machine:/home/chen/test1# cp -a /home/chen/test/b.py .root@chen-virtual-machine:/home/chen/test1# ls -l /home/chen/test/b.py b.py-rw-r--r-- 1 root root 0 9月 12 21:06 b.py-rw-r--r-- 1 root root 0 9月 12 21:06 /home/chen/test/b.py#加上-a选项，即将文件的所有特性都复制过来了。5.root@chen-virtual-machine:/home/chen/test1# cp -r /home/chen/test /home/chen/test1root@chen-virtual-machine:/home/chen/test1# lstest#加上-r选项，可以复制目录。但是文件与目录的权限可能会改变，随意一般还会加上-a选项，尤其是在备份的情况下 3) rm:删除文件或目录1234567891011121.root@chen-virtual-machine:/home/chen/test1/test# rm a.py#直接删除a.py文件root@chen-virtual-machine:/home/chen/test1/test# lsb.py2.root@chen-virtual-machine:/home/chen/test1/test# rm -i b.pyrm：是否删除普通空文件 'b.py'？ y#加上-a选项就会主动询问，避免你删除到错误的文件名3.root@chen-virtual-machine:/home/chen/test1/test# cd ..root@chen-virtual-machine:/home/chen/test1# lstestroot@chen-virtual-machine:/home/chen/test1# rm -r test#加上-r选项就可以删除目录 4) mv：移动文件或目录123456789101112131、root@chen-virtual-machine:/home/chen/test1# mv /home/chen/test/a.py /home/chen/test1root@chen-virtual-machine:/home/chen/test1# lsa.py#直接移动2、root@chen-virtual-machine:/home/chen/test1# mv a.py b.pyroot@chen-virtual-machine:/home/chen/test1# lsb.py#重命名3.root@chen-virtual-machine:/home/chen/test# mv -i /home/chen/test/a.py /home/chen/test1root@chen-virtual-machine:/home/chen/test# cd ~chen/test1root@chen-virtual-machine:/home/chen/test1# lsa.py b.py#加上-i选项就可以询问是否覆盖已经存在的目标文件 1.2.3Linux 文件内容查看Linux系统中使用以下命令来查看文件的内容： 1）cat 由第一行开始显示文件内容 123cat -A #可以将文件的内容完整的显示出来（包含如换行和[Tab]之类的特殊字符）cat -b #列出行号，仅针对非空白行号显示，空白行不标行号cat -n#打印出行号，连同空白也会有行号，与-b的选项不同 2）tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写 3） nl 显示的时候，同时输出行号 1234567891011121314151.nl -b #指定行号指定的方式，主要有两种：nl -b a #表示不论是否为空行，也同样列出行号(类似 cat -n)；nl -b t #如果有空行，空的那一行不要列出行号(默认值)；2.nl -n rz #行号在自己栏位的最右方显示，且加 0 ；root@chen-virtual-machine:/home/chen/test1# nl -b a -n rz b.py000001 print("hello.world:")000002000003 print（“I love python”）#自动补零，默认6位3.nl -w #行号栏位的占用的字符数root@chen-virtual-machine:/home/chen/test1# nl -b a -n rz -w 3 b.py001 print("hello.world:")002003 print（“I love python”）#变成仅有三位数 4）more 一页一页地显示文件内容 1234567891011121314151617181920212223242526272829301.root@chen-virtual-machine:/home/chen/slambook/slambook/ch10/ceres_custombundle# more ceresBundle.cpp#打开.cpp文件#include &lt;iostream&gt;#include &lt;fstream&gt;#include "ceres/ceres.h"#include "SnavelyReprojectionError.h"#include "common/BALProblem.h"#include "common/BundleParams.h"using namespace ceres;void SetLinearSolver(ceres::Solver::Options* options, const BundleParams&amp; params)&#123; CHECK(ceres::StringToLinearSolverType(params.linear_solver, &amp;options-&gt;linear_solver_type)); CHECK(ceres::StringToSparseLinearAlgebraLibraryType(params.sparse_linear_algebra_library, &amp;options-&gt;sparse_linear_algebra_library_type)); CHECK(ceres::StringToDenseLinearAlgebraLibraryType(params.dense_linear_algebra_library, &amp;options-&gt;dense_linear_algebra_library_type)); options-&gt;num_linear_solver_threads = params.num_threads;&#125;。。。。（中间省略）。。。。--更多--(19%) &lt;== 光标会在这里等待你的命令2.空白键 (space)：代表向下翻一页；3.Enter：代表向下翻『一行』；4./字串：代表在这个显示的内容当中，向下搜寻『字串』这个关键字；5.q：代表立刻离开 more ，不再显示该文件内容。 5）less 与 more 类似，但是比 more 更好的是，它可以往前翻页 less + 文件名 空白键：向下翻动一页； [pagedown]：向下翻动一页； [pageup]：向上翻动一页； /字串：向下搜寻『字串』的功能； ?字串：向上搜寻『字串』的功能； 6） head 只看头几行 12341.head -n number 文件#显示文件的前面number行2.head -n -number 文件#显示前面所有行，但不包括后面number行 7）tail 只看尾巴几行 12341.tail -n number 文件#显示文件的最后的number行2.tail -f 文件#表示持续侦测后面所接的文件（可能有新的数据一直写入），要等到按下[ctrl]-c才会结束tail的侦测 以上都是针对现有存在文件，假如要创建一个新的空文件就需要用到touch命令 1touch 文件 1.3 文件与文件系统的压缩1.3.1解压缩目录：tartar可以将多个目录或文件打包成一个大文件，同时可以通过gzi、bzip2、xz的支持，将该文件同时进行压缩。 1234567891.压缩：tar –zcvf filename.tar.gz dirname解压：tar –zxvf filename.tar.gz#通过gzip的支持进行压缩/解压缩：此时文件名最好是*.tar.gz2.压缩：tar –jcvf filename.tar.bz2 dirname解压：tar –jxvf filename.tar.bz2#通过bzip2的支持进行压缩/解压缩：此时文件名最好是*.tar.bz23.压缩：tar –Jcvf filename.tar.xz dirname解压：tar –Jxvf filename.tar.xz#通过xz的支持进行压缩/解压缩：此时文件名最好是*.tar.xz 更多有关linux命令的教程：http://www.runoob.com/linux/linux-command-manual.html 2．Vim编辑器及其配置除了查看文件内容外，我们还需要对文件中的内容进行编辑。Linux自带的编辑器有nano和vi，但vi编辑器使用起来很不方便，我们需要先下载vim编辑器，它是vi编辑器的升级版，更人性化些。 2.1vim的安装和使用1)首先更新索引源： 1sudo apt-get update 2)安装vim编辑器: 1sudo apt-get install vim 3）打开文件、保存、关闭文件（vim命令模式下使用） vi filename #打开filename文件，此时是命令模式 w #保存文件 q #退出编辑器，如果文件已修改请使用下面的命令 q! #退出编辑器，且不保存 wq # 退出编辑器，且保存文件 4）插入文本或行(vim命令模式下使用，执行下面命令后将进入插入模式，按ESC键可退出插入模式) a #在当前光标位置的右边添加文本 i #在当前光标位置的左边添加文本 A #在当前行的末尾位置添加文本 I #在当前行的开始处添加文本(非空字符的行首) O #在当前行的上面新建一行 o #在当前行的下面新建一行 R #替换(覆盖)当前光标位置及后面的若干文本 J #合并光标所在行及下一行为一行(依然在命令模式) 5) 设置行号(vim命令模式下使用) set nu #显示行号 set nonu #取消显示行号 6)注意vim命令模式下，想要输入命令，得先输入“：”。 2.2 vim编辑器显示高亮未配置vim时文档的显示无高亮，无行号，体验极差，为了增加高亮，改善体验。 1）我们可以先用SecureFx将《三个工具实现PC端远程连接、桌面共享和文件传输》一文百度文分享链接中的vimconfig.tar.gz传送到/home/用户名/目录下 2）在命令行模式下输入tar xvf vimconfig.tar.gz 解压压缩包 3）进入vimconfig目录中运行config.sh脚本 4）可能会报错，我们需要输入命令sudo /home/mrchen/.vim /home/mrchen/.vimrc,然后再运行./config.sh,然后再运行apt-get install ctags。 上面命令就是在/home/用户名/目录下新建.vim文件和.vimrc文件。 然后在加载ctags包。 5）最后，disconnet然后重新连接登陆就可以了，然后再用vim打开文本文件，即可打开新世界。]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七个Windows工具提升你的办公、开发效率]]></title>
    <url>%2F2019%2F08%2F31%2F%E4%B8%83%E4%B8%AAWindows%E5%B7%A5%E5%85%B7%E6%8F%90%E5%8D%87%E4%BD%A0%E7%9A%84%E5%8A%9E%E5%85%AC%E3%80%81%E5%BC%80%E5%8F%91%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[七个Windows工具提升你的办公、开发效率 工欲善其事，必先利其器。 好的办公工具不仅能提升个人的工作效率，更能提升个人工作的幸福感。这里介绍七款工具，全面助力你的办公、开发。 1.Clover 痛点：我们在不同文件夹之间进行操作时，一两个文件窗口还好。随着工作量的增加，陆陆续续会跳出来许多窗口，这时候我们很有可能就会忘记我们要找的文件对应哪个窗口。又得遍历一遍，效率低下。 在这里介绍Clover工具。 推荐理由：Clover 是 Windows Explorer 资源管理器的一个扩展，为其增加类似谷歌 Chrome 浏览器的多标签页功能。这样我们就可以类比浏览器把不同文件夹当成不同网页使用。 基本使用： Ctrl+T新开页面 Ctrl+W关闭页面 Ctrl+Tab切换页面 Ctrl+D添加当前路径到书签栏，下次可以直接点击打开。 2.Listary 痛点：我们在查找某个文件时可能要翻山越岭经过若干文件目录，最后找到一个.docx文档；随着装的软件越来越多，电脑桌面图标也越来越多，直到整个桌面都是快捷方式。 在这里介绍Listary工具。 推荐理由：Listary 是一项革命性的搜索工具 ，它使得寻找文件和应用程序启动速度极快。 基本使用： 在几乎任何界面键盘输入两次 ctrl 键 ， 输入文件夹/文件/程序名，上下选择+回车即可打开文件夹/文件/程序，还您一个干净整洁的桌面。同时，它还支持模糊搜索，比如输入七个，就可以搜索出本文文档。 在刚刚上下选择某一文件/文件夹/程序名后，只要按下方向键右键。你会立即看到文件的右键菜单弹出。然后就可以对应的提示做出操作。 右边有三个扩展的功能键，分别是收藏夹显示之前收藏过的快捷方式；历史纪录显示查询过的快捷方式，命令是一些扩展功能，比如一键打开CMD命令行窗口等。 网站关键词+内容可以实现快速搜索，比如想在百度上搜索“如何编写MarkDown文档”，在搜索栏中输入bd + 如何编写MarkDown文档，即可。 这里有一些软件自带的关键词。比如，刚刚使用的bd。 3.Snipaste Windows自带截图、QQ有截图功能、网页也有截图。可是，可是，Snipaste这款工具截图真的太好用了。 推荐理由：Snipaste 是一个简单但强大的截图工具，也可以让你将截图贴回到屏幕上！下载并打开 Snipaste，按下 F1 来开始截图，再按 F3，截图就在桌面置顶显示了。就这么简单！ 基本使用： 强大的截图，它可以自动检测截图窗口大小，比如可以截出完美的矩形框。 把图片贴到屏幕上，把图片作为窗口置顶显示。 方便地标注图像， 支持矩形、椭圆、 线条、 箭头 、 铅笔 、 马克笔 、 文字，还有马赛克、 高斯模糊、橡皮擦。 自定义设置，右击Snipaste选择首选项，即可进行丰富的设置。 4.Rolan 推荐理由：这款软件可以将文件夹/文件/应用程序拖动到窗口进行分类，最主要的是他可以贴边隐藏，随时呼出。 这款软件和Listary有异曲同工之妙。和Listary搭配使用，基本上能在最快的时间内找到你需要的文件夹/文件/应用程序并打开；同时最大程度上减少桌面图标数量（我自己本人桌面只有一个回收站(｡･ω･｡)）。 5.uTools 推荐理由:uTools 是一款极简、插件化、跨平台、现代化的桌面增强效率软件，它有两个最大的特点，第一个就是快速呼出，按下键盘快捷键(默认 Alt+空格)，即可呼出输入框。第二个就是丰富的插件，作者将 uTools 设计成“一切皆插件”，所有的功能都由插件来提供。下面就让我们来看看丰富的插件吧。 通用 在线翻译，为中英文翻译，简单快捷。 todo，可以快速呼出的待办事项清单，随时记录大小事务。 图片 图床 ​ 一般在用MarkDown写文章的时候，对于图片是从本地传的文档在另一电脑上图片就加载不出来。这时候需要把图片放到第三方，别人打开文档就可以看到加载的图片，相当于从第三方下载的图片，这个第三方就被称为图床。 ​ 如下图，点击上传标志即可上传。 ![Snipaste_2019-05-20_21-40-32.png](http://yanxuan.nosdn.127.net/af02b4bfbe10356e14b16a0380e7eed4.png) 图片转文字，是OCR拍照识字没错了。 开发 编码小助手 无论是开发者还是学习编程的爱好者，都经常遇到需要对各类字符串进行编码的情况。uTools 的编码小助手插件包含了 时间戳转换、uuid、hash加密、base64、进制转换等功能，可以大大提高大家写代码的效率。 使用：ALT + 空格呼出软件。在插件中心下载需要的插件，在已安装打开插件，点击红色方框处即可使用。 前面介绍的Listart、Snipaste、Rolan、uTools强烈建议设置为开机自启动，这样的话就可以直接通过快捷键呼出软件啦，而不需要慢慢找到图标再打开软件。 6.Bandizip Windows版 推荐理由：这是一款压缩包软件，和其他压缩包不同的是它支持压缩预览。只要点击右键就可以实现压缩文件预览。 7.PotPlayerMini 推荐理由： 它无需安装，双击可执行文件即可运行播放印音频/视频，启动速度快。 内置强大的解码器（普通用户无需安装第三方解码器即可播放主流格式的视频文件，支持BD和MKV大视频文件的播放。），播放过程稳定，对付高清大片没有任何问题。 对字幕的支持也很不错，再加上给力的各种皮肤以及相应的Direct3 D9皮肤机制让其在同一款皮肤下的播放形式有了更多一层的表现力，可塑性极强。 介绍了炒鸡好用的软件，那么问题来了，怎么样能以最快的速度下载安装好这些软件呢？ 公众号后台回复“办公效率工具”即可获得百度云链接。 然后就可以开始你的效率人生啦，时间就是金钱！]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五个Windows工具提升你的学习、科研效率]]></title>
    <url>%2F2019%2F08%2F26%2F%E4%BA%94%E4%B8%AAWindows%E5%B7%A5%E5%85%B7%E6%8F%90%E5%8D%87%E4%BD%A0%E7%9A%84%E5%AD%A6%E4%B9%A0%E3%80%81%E7%A7%91%E7%A0%94%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[五个Windows工具提升你的学习、科研效率 工欲善其事，必先利其器。 1.引言我在之前的文章《七个Windows工具提升你的办公、开发效率》推荐了七个Windows工具来助力办公、开发工作。（以下内容会用到之前文章中推荐的工具，以下简称文章为《七个》）事实上，除了办公、开发，我们还需要适时地充电学习来应对新知识不断涌现的时代。这里主要针对两种学习场景，一种是看视频做笔记，另一种是看论文学习。 2.视频笔记2.1视频截图（任何视频格式）推荐：使用PotPlayer（《七个》文章推荐）播放视频，截图有个快捷键：ctrl+c，即可将当前视频画面（不含字幕）复制到剪贴板，然后再拷贝到Word等编辑器；也可以在播放视频的时候用Snipaste（《七个》文章推荐）截取部分画面（比如大段的文字或者字幕），然后复制到uTools（《七个》文章推荐）软件当中的OCR插件中提取文字，然后再将提取的文字复制到笔记上。 2.2视频字幕（.mkv视频格式）痛点：2.1提到了可以提取字幕的方法，但是如果需要提取一节视频的所有字幕生成文件（一般是.srt）；或者对于一些“生肉”教学视频，需要批量封装字幕。这里推荐两个工具，可以批量封装和批量提取字幕。 推荐：Mkvtoolnix-mmg和Mkvtoolnix-MKVExtractGUI2 使用：具体使用和注意事项可以参考使用mkvtoolnix批量封装和批量提取字幕。 3.论文学习3.1论文下载痛点：在学校可以很轻松的凭借校园网下载大量的学术论文，一旦离开学校想下载论文就需要付费下载，也就是“知识就是金钱”。有人提出可以让在校的同学帮忙下载，但是毕竟不是长久之计，这里提供几种方法可以免费下载论文。 推荐一：谷粉学术 使用： 1）打开官网，输入想要查询的关键词，如“deep learning”，然后点击谷粉学术。 2）然后如果出现[pdf]字样，可以直接点击。 3）然后如果出现[sci hub 下载] 字样，可以直接点击。 4）然后在跳转的页面进一步操作，即可下载到pdf学术文档。 注意： 1）该网站针对国外英文文献有大量的下载资源链接，但是对国内的很多文献找不到下载。如输入”深度学习“搜索字样。所以在查找国内文献无法找到下载链接的情况下建议使用推荐二。 2）其他的如使用PubMed号、DOI号搜索下载论文可以参考这篇文章。 推荐二：浙江图书馆 使用：我是在同事的推荐下知道浙江图书馆的，具体的注册和使用方法可以参考这篇文章。 注意：在使用知网时会提示“当前并发用户数已满”。知网是有并发用户数限制的，当用户已满的时候就会出现这样的情况，一般是使用数据库的人比较多，可以过一会再尝试；另外许多论文是好几个数据库都收的，知网忙的时候不妨转用万方、维普等数据库。 3.2论文管理——Zotero痛点：阅读大量的paper是磕盐工作者一项基本的工作，尤其是在做一项课题研究的初期。有些论文我们在读过一遍时就会将其丢在一堆文档中，当我们想再次查阅时就会变得特别不方便；或者当我们自己要写一篇论文时，可能要打开数十个网页来导出参考文献，然后再将内容复制到Word中编辑。 推荐理由：可以前期就对文献做了细致的管理和标记，方便后面查阅；可以轻松插入引用上标，一键导入所有参考文献。 基本使用： 1）首先是从官网下载安装该软件。（百度云提供下载） 2）打开软件界面，鼠标右键点击我的文库-&gt;新建分类 3）如果是英文文献，就直接将下载好的英文论文PDF文档拖入标题一栏，然后会自动填充信息，还可以针对文献做笔记。 4）如果是中文文献，首先导出.blb文件后用记事本打开并复制里面的全部内容 然后在文件中选择从剪切板导入 然后将中文论文PDF文件鼠标拖至刚导入文件成为其子文件 5）标题一栏中的PDF文档是可以直接打开看的；还有搜索功能，即假如标题界面一共有30篇论文，可以输入关键字搜索。 6）然后就是自己编写论文，需要引用文献。首先是选择合适的样式，这里推荐“Chinese Std GB/T 7714-2005(numeric,Chinese)”，比较符合国人写论文的习惯。首先从这个网站将该样式下载下来，下载文件为.csl格式。 7）然后加载样式。打开Word-&gt;选择Zotero-&gt;Document Preference-&gt;Zotero - 文档首选项(管理样式)-&gt;Zotero 首选项(获取更多样式) -&gt;点击加号 加载.csl文件 8）然后插入上角标。鼠标光标置于要插入上角标处-&gt; Zotero-&gt; Add/Edit Citation -&gt; 选择样式 光标处出现{Citition字样}，并选择经典视图 选择对应文献，点击OK后就会出现上标。然后依次添加其他上标。 9）最后一键导入所有参考文献内容。鼠标光标置于要导入参考文献处-&gt; Zotero-&gt; Add/Edit Biliography 10)最终效果图 11) 数据存储位置设置 因为随着使用时间增长，文献库会日渐庞大，因此不建议直接使用默认的数据存储位置（C盘）。这个也可以在【编辑-首选项-高级-文件和文件夹】栏目下进行修改，选择数据存储位置-自定义，然后选择目标目录即可。之后会提示你需要手动将Zotero原数据库下的文件移动到新目录下，这个很方便，可以直接点击打开数据文件夹，然后将里面的内容全部移动到目标文件夹下就可以了。 介绍了炒鸡好用的软件，那么问题来了，怎么样能以最快的速度下载安装好这些软件呢？ 公众号后台回复“科研效率工具”即可获得百度云链接。 然后就可以开始你的效率人生啦，时间就是金钱！]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cmake使用教程]]></title>
    <url>%2F2019%2F05%2F23%2FCmake%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"></content>
      <categories>
        <category>工具</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于Typora的Markdown编辑器使用教程]]></title>
    <url>%2F2019%2F05%2F12%2FTypora%EF%BC%9A%E6%9E%81%E7%AE%80Markdown%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1.MarkdownMarkdown以简单的语法深受写作朋友的喜爱，尤其是对程序代码输入的支持更加方便了程序员写技术博客。此外它让写作回归到内容本身，而不是以富文本（word、秀米等）为主流的对排版的专注。 Markdown可以实现一篇文章，跨平台使用。即在Markdown编辑器里面写好后，可以直接一键复制到简书，知乎，CSDN，Github，有道云笔记等平台。如果是需要复制到微信公众号里的话，就需要借助MarkDown转微信公众号工具。 2.Typora主要功能介绍上文提到Markdown编辑器，我个人使用的是Typora，这是一款所见即所得的工具，并且它还支持将写好的Markdown文章轻松转换成PDF和HTML文件等其他格式，转成PDF文件时会自动按照标题生成书签和目录。 如果需要的话，可到官网下载Typora这款软件。 2.1 字体效果​ 强调:在要强调内容前后分别加两个“*”号。 下划线:快捷键Ctrl+u。 斜体：内容前后分别加一个“*”号。 代码：先转化成英文输入法，再把内容前后分别加上一个“`”号。 import cv2 删除内容（切换完成状态）：先转化成英文输入法，再把内容前后分别加上两个“~”号。 高亮：内容前后分别加两个“=”。 文字跳转链接：先转化成英文输入法，输入中括号+小括号，中括号里面填文字内容，小括号里面填网页链接。 2.2 段落效果 有序列表：输入数字“1”+“.”+空格 ， 自动开始有序列表。 无序列表：输入“+”或“-”或“*”+空格，自动开始无序列表。 段落引用：Ctrl + Shift +Q。 标题：Ctrl+0~6即可实现对应的段落到六级标题。 2.3 插入 代码块：先转化成英文输入法，再把内容前后分别加上三个“`”号。 针对不同编程语言配备不同的代码高亮和横向滚动条，还可以自己设置背景颜色。 123456import matplotlib.pyplot as pltimport matplotlib.image as mpingimport numpy as npimport cv2from moviepy.editor import VideoFileClipfrom pylab import axis 表格:Ctrl+T。 在弹出的对话框中选择行列数，自动生成列表。还可以很方便地对表格进行编辑。 图像：直接将本地或者网页图片拖到光标处即可。 水平分割线：输入三个或三个以上“-”（“*”），再按回车键，即出现一条分割线。 内容目录：[toc] + enter 2.4数学公式首先在文件-&gt;偏好设置里将Markdown扩展语法打钩。 2.4.1公式输入神器——Mathpix Snip输入数学公式应该是一件令人头疼的事，特别是大段的数学公式。在这里推荐Mathpix Snip ，可以从它的官网下载。说它是神器，主要是我们只需要截个图，公式会自动转化为 LaTex 表达式，然后再进行复制就可以，大大提高了效率。 使用：启动软件后，使用快捷键CTRL+ALT+M即可开始截图，图源可以来自文档、视频、手写体。 2.4.2内联公式复制第二行代码，即$代码$，点copy即可，光标点到输入公式的地方，直接粘贴。 2.4.3公式块复制第三行代码，即$$代码$$，点copy即可，光标点到输入公式的地方，直接粘贴。 2.4.4延伸如果想深入学习关于数学公式的Markdown表达，可以参考这篇博客。 2.5HTML页面 嵌入Bilibili视频 123456789&lt;iframe height=450 width=800 src="//player.bilibili.com/player.html?aid=32640707&amp;cid=57118032&amp;page=1" scrolling="no" border="0" frameborder="0" framespacing="0" allowfullscreen="true"&gt; &lt;/iframe&gt; 以上文本可以从B站视频分享中找到。 嵌入腾讯视频 123456&lt;iframe height=450 width=800 src="https://v.qq.com/txp/iframe/player.html?vid=j00301d62s4" frameborder=0 allowfullscreen&gt; &lt;/iframe&gt; 以上文本可以从腾讯视频分享中找到。 嵌入音频(T＿T) 1&lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&amp;id=864711417&amp;auto=1&amp;height=66"&gt;&lt;/iframe&gt; 以上文本可以从网页版网易云音乐生成外链播放器获取。 2.6其他 插入表情：ctrl + shift + b插入颜文字表情（搜狗输入法），插入emoji表情（使用微软输入法） 主题，在官网选择自己喜欢的主题，下载下来，通常是个压缩包，解压后放入 Typora 的主题文件夹（文件-&gt;偏好设置-&gt;主题-&gt;打开主题文件夹），重启 Typora 就可以使用了。 3.总结 轻量级极简免费功能强大的Markdown编辑器。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Typora</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派入门之开机配置、远程操作]]></title>
    <url>%2F2019%2F05%2F11%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1.引言 树莓派是为学习计算机编程教育设计的一种只有信用卡大小的微型电脑，其系统基于Linux。随着Windows 10 IoT的发布，我们也将可以用上运行Windows的树莓派。 树莓派的系统是安装在SD卡里的，只需插上SD卡、接通显示器和键盘鼠标，就能执行如电子表格、文字处理、玩游戏、播放高清视频等PC的基本功能。 个人选择树莓派，主要想用来打通Linux的基本编程知识以及嵌入式硬件知识，另外相应的做一些简易创客项目。 2.系统安装 2.1 安装包（百度云提供下载链接）首先是下载所需要的树莓派系统镜像和安装烧写镜像的工具，当然也可以从官网下载最新的Raspbian树莓派系统。 此外，还有本文树莓派登录控制提到的其他软件。 2.2 树莓派系统镜像烧写1）解压下载的树莓派系统文件，得到img镜像文件； 2）将SD使用卡托或者读卡器后，连上电脑； 3）直接点击安装Win32DiskImager-0.9.5-install.exe并运行； 4）在软件中选择img文件，“Device”下选择SD的盘符，然后选择“Write”； 5）然后就开始安装系统了，根据你的SD速度，安装过程有快有慢。 6）安装结束后会弹出完成对话框，说明安装就完成了，如果不成功，请关闭防火墙一类的软件，重新插入SD进行安装。 2.3 Windows下备份（还原）树莓派树莓派支持许多操作系统，针对不同需求在不同系统上做相应的配置，我们可以通过购买若干张SD卡。当然我们也可以实现一张卡的重复使用，也就是说我们可以把原先系统的内容完整拷贝到Windows下，下次再用我们就再将原先系统内容烧录到SD卡即可。同样，还是上文提到的Win32DiskImager-0.9.5-install.exe可以实现该功能。 先新建一个空白的.img后缀的文件，然后选择直接read就可以备份系统了，到时再重装就可以恢复了。 3.基本设置3.1 换源树莓派默认的下载源是国外的源，每次下载时速度都比较慢，因此我们可以从国内已经下载了这些资源的人那里获取，比如说，清华大学开源软件镜像站。 1）给Raspbian的包管理器apt-get换源在树莓派的命令行界面输入： 1sudo vim /etc/apt/sources.list 在第一行开头加一个#注销其内容，然后把下面的内容拷贝到最后一行之后，如图中的效果： 12deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpideb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ stretch main contrib non-free rpi 再输入以下命令更新到清华大学镜像源最新的软件列表。 1sudo apt-get update 以上步骤实现了Respbian的包管理器apt-get换源到清华大学软件镜像站，并更新了软件列表，今后在树莓派命令行中执行sudo apt-get install 软件名时便会自动从清华大学开源软件镜像站高速下载。 2）给Python的第三方模块安装工具pip换源在树莓派的命令行中依次输入运行以下三个命令 123sudo mkdir ~/.pip #root目录下建立.pip文件夹cd .pip sudo nano pip.conf 在打开的文件中输入以下内容，如图中的效果： 12345678[global]timeout = 10index-url = http://mirrors.aliyun.com/pypi/simple/extra-index-url= http://pypi.douban.com/simple/[install]trusted-host= mirrors.aliyun.com pypi.douban.com 3.2树莓派启动烧写完后把SD卡直接插入树莓派接通电源即可运行，此时我们需要连接显示器。 打开如图： 3.3 配置WIFI基本操作：接上鼠标，选择左上角树莓派标志-&gt;首选项-&gt;Raspberry Pi Configuration-&gt;Localisation-&gt;WiFi Country设置Country为CN China。 重启后，在右上角选择WIFI，输入密码即可连接。 拓展：设置树莓派开机后自动连接无线网络（从第二次开始无需显示器）。 1）在联网状态下（首次需要连接显示器），打开终端，安装vim编辑器。 sudo apt-get install vim 2）切换到root用户（部分文件我们是没有权限的，这时需要获取root用户的权限，可以通过sudo来临时获取最高权限，或者切换到root用户，） 3）然后进入目录/etc/wpa_supplicant/wpa_suppliacant.conf.进行编辑。下图是编辑完成后以界面文件形式打开。 ssid是无线网络名称，psk是密码，key_mgmt是加密方式（可省略），priority是优先级。 可以设多个WiFi，赋予不同的优先级，数字越大，优先级越高。 我设两个，第一个是手机热点，第二个是路由器WiFi，一个断网会自动切换到另一个。 3.4 本地化设置进入左上角树莓派标志-&gt;首选项-&gt;Raspberry Pi Configuration-&gt;Localisation进行相应的设置。 1）系统语言设置 2）系统时区时间设置 3）系统键盘布局设置 当然，也可以在终端完成这一切设置，详细可见这篇博客。 4.树莓派的登录控制4.1 SecureCRT1）官方的树莓派系统没有开启SSH服务，需要我们人为的开启SSH服务，我们需要在HDMI显示器上的命令行终端上输入sudo raspi-config进入到树莓派系统配置界面。 2）打开命令行终端，输入ifconfig查看我们的ip地址。 3）在电脑端打开软件SecureCRT和SecureFX并连接ip地址。这样就可以实现远程控制树莓派了。 4.2 VNC Viewer1）首先确认树莓派打开VNC，打开树莓派命令行界面输入命令，进入树莓派配置界面。 1sudo raspi-config 第五行：Interfacing Options开启功能 第三行VNC：VNC远程桌面登陆。 2）安装好VNC Viewer，确保树莓派和主机连在同一个网络下。 3）打开VNC Viewer，输入IP地址，回车即可。 4）跳出授权界面，正常填写树莓派用户名和密码即可。 5）点击ok即可进入界面。 6）另外还需设置一下分辨率，输入命令 1sudo vim /boot/config.txt 找到如下两行，将其设置为自己电脑的分辨率即可。比如我的电脑是1920x1080。 12framebuffer_width=1920framebuffer_width=1080 7）重启就可以像自己笔记本一样正常显示了。 4.3 TeamViewer关于树莓派登录控制提到的三个软件更详细的使用方法可以参考《三个工具实现PC端远程连接、桌面共享和文件传输》。 5.树莓派配置并使用USB摄像头。将USB摄像头外接在树莓派，打开终端，输入：lsusb 终端继续输入sudo apt-get install fswebcam 下载完成后，终端输入fswebcam --no-banner -r 640*480 camera.jpg可以在/home/pi目录下生成一个当前摄像头拍摄到的实时照片。以此证明USB摄像头工作正常。 介绍了和树莓派搭配使用的软件，那么问题来了，怎么样能以最快的速度下载安装好这些软件呢？ 公众号后台回复“树莓派基本工具”即可获得百度云链接。 对基本编程感兴趣的童鞋不能错过树莓派幺！]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Win10环境下安装GPU版TensorFlow-显卡RTX2060.md]]></title>
    <url>%2F2019%2F04%2F21%2FWin10%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85GPU%E7%89%88TensorFlow-%E6%98%BE%E5%8D%A1RTX2060%2F</url>
    <content type="text"><![CDATA[前言 目前由于工作需求需要跑跑深度学习数据集。这里介绍两种配置的tensorflow-gpu环境的搭建。 正文 环境一 win10_64 tensorflow1.4 cuda8.0 cudnn6.0 GTX1050 python 3.6 参考win7_64+tensorflow1.4+cuda8.0+cudnn6.0+GTX1050安装 Win10下Tensorflow(GPU版)安装趟坑实录 参照这两个连接可以完美安装tensorflow-gpu。 环境二 RTX2060 win10 Tensorflow GPU CUDA 9.2 CUDNN7.2 python 3.6 安装1.Anaconda3下载与安装下载Anaconda3-5.2.0-Windows-x86_64并安装。 记得打勾！！两个都要勾上。 2. VS2017 下载与安装我这里下载的是Windows Community 2017版，下载完成后双击进行安装，安装C++的编译器。 其实不一定非要装vs，只是需要vc++框架即可，可在“控制面板\程序\程序和功能\卸载程序”里查看。 3.CUDA10.0下载与安装在电脑桌面鼠标右击依次打开”NVIDIA控制面板-&gt;”系统信息”-&gt;”组件”，查看适合本电脑的CUDA驱动版本。 在NVDIA官网下载对应版本的CUDA，这里我选择的是“CUDA Toolkit 10.0版本 ”，选项为： 4、CUDNN7.3.1下载与安装官网下载https://developer.nvidia.com/rdp/cudnn-archive 这里可能需要注册登录填个调查文件啥的。 这里我们选择cuDNN v7.3.1的版本 选择的依据是来源于github：https://github.com/fo40225/tensorflow-windows-wheel 由于我使用的tensorflow-gpu版本是1.12.0，python版本是3.6，CUDA版本是10.0。故选择cuDNN v7.3.1的版本。 到这里下载完成！完成后咱们开始解压，然后将相应的包，放到cuda相应包底下。!咱们只需要拿出这些文件夹里面文件放到想要cuda文件夹即可，我的cuda文件夹地址为：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0 5.创建并激活运行环境创建运行环境，输入指令： 1conda create -n tensorflow-gpu python=3.6 新建一个名字叫“tensorflow-gpu”，python版本为3.6的运行环境，此环境与Anaconda中其它环境隔离。然后输入“y“和回车后开始安装。 安装完成后会生成新的文件夹，可以此为依据查看自己是否创建成功。 激活并进入环境，使后续指令在激活的环境中生效，输入指令： 1conda activate tensorflow-gpu 注意：base和tensorflow-gpu是两个不同的运行环境，两个环境的安装包互不干涉。如果需要pip install 安装包，需要先切换到对应的运行环境下。(比如下文的pip install tensorflow-gpu安装包得先切换到对应运行环境下。) 升级pip到最新版，输入指令： 1python -m pip install --upgrade pip 6、tensorflow-gpu 安装github这个地址里面按照我下图的选择版本 下载，桌面弄个文件夹下，下载到文件夹内。然后在文件夹内按着shift键，右击空白地方，选择 在此处打开Powershell,然后在命令窗里输入： 1pip install tensorflow_gpu-1.12.0-cp37-cp37m-win_amd64.whl 使用conda list查看安装情况，看到了tensorflow-gpu说明已经安装完成。 7.测试 8.结果 已经能够识别出RTX2060显卡了，并成功输出！ 后记 enjoy yourself~]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>GPU</tag>
        <tag>Win10</tag>
        <tag>RTX2060</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware Tools安装教程]]></title>
    <url>%2F2019%2F04%2F21%2FVMware%20Tools%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言 使用虚拟机下安装linux系统的人都有这样的感受，感觉Linux系统界面太小，无论是打开浏览器还是终端，都感觉很压抑，并且无法很好地在Linux和Windows之间传送文件。前文给出了使用SecureCRT控制Linux终端以及传送文件的方法，本文将给出在Linux里实现界面文件轻易传送并且实现自适应调整大小的方法。 正文 1.环境 Windows10 VMware-workstation-full-14.0.0.24051 ubuntu-18.04.1-desktop-amd64 2.方法 首先是打开虚拟机，在菜单栏找到“虚拟机(M)”选项，并在其子菜单中选择“安装VMware Tools(T)…”(注意是要在虚拟机启动的状态下进行),弹出如下图所示的提示框，点击【是】。 点击左侧任务栏中的”files“，然后从上往下找到“VMwareTools”。点击进入会有一个“VMwareTools-10.1.6-5214329.tar.gz”的压缩包文件，将此文件提取（解压）到桌面。 注意：如果提取出现“Not enough free space to extract VMwareTools-10.1.6.-5214329”这样的报错。就需要把VMwareTools-10.1.6.-5214329.tar.gz复制到桌面再进行提取。 解压后会出现一个“vmware-tools-distrib”，进入并找到”vmware-install.pl“的脚本文件， 该文件就是安装vmware tool的脚本文件； “Ctrl+Alt+T”打开终端（命令行），进入到vmware-install.pl文件所在的目录下，运行命令执行该perl 脚本： 1sudo ./vmware-install.pl 按提示信息一步步走，也可全部按回车进入下一步，直到出现如下信息：“Enjoy——the VMware team”，至此VMwareTools终于安装完成了。 3.重启虚拟机 和ubuntu18.04系统接着还需要设置： 虚拟机界面 菜单栏找到”查看”-&gt;”自动调整大小”-&gt;”自动适应客户机大小”,选定它； 这样一来就可以实现了： 使用户可以在物理主机和虚拟机之间直接拖动文件。 避免了在物理机和虚拟机之间必须使用CTRL切换，我们不必使用键盘切换，直接便可退出，使得虚拟机真正成为了电脑的一部分。 使得界面充满整个VMware虚拟机，看着更舒适。 后记 enjoy yourself~]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>VMware Tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三个工具实现PC端远程连接、桌面共享和文件传输]]></title>
    <url>%2F2019%2F04%2F17%2F%E4%B8%89%E4%B8%AA%E5%B7%A5%E5%85%B7%E5%AE%9E%E7%8E%B0PC%E7%AB%AF%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E3%80%81%E6%A1%8C%E9%9D%A2%E5%85%B1%E4%BA%AB%E5%92%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[1.引言 一般情况下，我们在连接虚拟机的终端或者访问服务器或者连接另一台计算机需要不同程度的实现远程连接终端、桌面共享和文件传输。这里介绍不同程度的可以实现上述功能的3款软件。 2.SecureCRT SecureCRT 是一款可以实现远程连接终端和文件传输的软件。它发挥作用的前提是主机和远程主机必须在同一网段内。比如，下图是我用该软件来控制电脑的Linux虚拟机终端。 2.1 安装（百度云提供下载）1）双击安装程序进行安装（第一个文件是SecureCRT8.1.0 64位安装程序，第二个文件是SecureCRT注册机，第三个文件是SecureFX注册机。） 2）点击next 3）进入license agreement，选择 I accept…，点击next 4）点击next 5）这里我选择Custom（自定义安装），点击next 6）点击“change”更改自己的安装路径，然后点击next 7）这里我没勾选生成桌面快捷方式，点击next 8）点击install，开始安装，等待安装完成 9）安装完成后，先不要运行，点击finish 10）此时在开始菜单会看到若干图标，如下图 到这里，SecureCRT、SecureFX安装已经完成了。 2.2 破解1）解压注册机的压缩文件，将程序复制到SecureCRT的安装目录下（注意：电脑杀毒软件如果会把程序删除掉，需要先将杀毒软件关闭），如下图： 2）双击打开SecureFX keygen.exe，如下图，点击patch 3）点击path 选择 SecureCRT.exe进行替换，之后会继续弹出一个窗口，然后选择LicenseHelper.exe，之后会弹出替换成功的信息。选择完成后点击generate，生成注册码 4）接着回到开始菜单双击执行SecureCRT程序，选择文件数据存储位置，点击OK 5）接下来按照以下步骤即可 6）将注册机生成的信息按照提示复制粘贴过去 依次复制Name、Company、Serial number、License key、Issue date。 7）复制完后点击“完成” 8）接下来会让你填写登陆SecureCRT的账号密码，填写后每次打开SecureCRT需要登陆账号密码，这里我选择不填写 9）到这里SecureCRT破解已经完成了，接下来你就可以使用啦！ 10）SecureFX的破解方法同SecureCRT的破解类似。 2.3 使用1）点击开始菜单SecureCRT8.1快捷方式，输入Linux主机或远程主机的IP地址和用户名，点击“connect”连接，按照提示根据自己的需要选择，之后填写密码，点击“OK”即可连接使用！ 注意：一台Win10可以同时连接多个远程主机，如Session下面有三个IP地址就代表三个远程主机。 2）点击开始菜单SecureFX8.1快捷方式，选择IP地址即可。 然后就可以在Win10本地和Linux系统之间拖动传输文件，非常方便。 3）其实单独使用SecureCRT8.1就可以实现本地和Linux之间的文件互传，但总觉得没有拖动来的方便。有兴趣的可以往下读。 4）SecureCRT8.1实现本地和Linux之间的文件互传 SecureCRT 按下ALT+P就开启新的会话 进行ftp操作。 我们要想下载或上传某个目录下的文件，首先要cd 到该文件所在文件的目录下，然后使用 get（将远程目录中文件下载到本地目录）或put（将本地目录中文件上传到远程主机） +文件名的命令来下载或上传。 2.4 显示高亮2.4.1 界面显示高亮SecureCRT连接Linux后显示就是黑白，体验感极差。 我们可以做些基本设置，提升体验感，具体的设置可以参照这篇文章。 2.4.2 vim编辑器显示高亮未配置vim时文档的显示无高亮，无行号，体验极差，为了增加高亮，改善体验。 1）我们可以先用SecureFx将百度文分享链接中的vimconfig.tar.gz传送到/home/用户名/目录下 2）在命令行模式下输入tar xvf vimconfig.tar.gz 解压压缩包 3）进入vimconfig目录中运行config.sh脚本 4）可能会报错，我们需要输入命令sudo /home/mrchen/.vim /home/mrchen/.vimrc,然后再运行./config.sh,然后再运行apt-get install ctags。 上面命令就是在/home/用户名/目录下新建.vim文件和.vimrc文件。 然后在加载ctags包。 5）最后，disconnet然后重新连接登陆就可以了，然后再用vim打开文本文件，即可打开新世界。 2.5 问题再来详细谈谈第2.3步 使用的第一小步。 1）查看自己Linux的IP地址：“Ctrl+Alt+T”打开Linux系统的终端，输入ifconfig 2）可能出现的情况： 3）如果SecureCRT出现“The remote system refused the connection”，如果你遇到这个问题，说明你的Linux系统里面没有安装openssh-server ​ 查看Linux端的当前进程： ​ 显示只有一个进程。 ​ 安装openssh-server ​ 再次查看Linux这端的当前进程： ​ 有两个进程。 ​ 问题解决，再次尝试即可连接成功 3. VNC Viewer VNC Viewer 是一款可以实现远程桌面共享的软件。它发挥作用的前提是主机和远程主机必须在同一网段内。比如，下图是我用该软件来在本地共享树莓派桌面。 1）首先确认树莓派打开VNC，打开树莓派终端界面输入命令，进入树莓派配置界面。 1sudo raspi-config 第五行：Interfacing Options开启功能 第三行VNC：VNC远程桌面登陆。 2）安装好VNC Viewer，确保树莓派和主机连在同一个网络下。 3）打开VNC Viewer，输入IP地址，回车即可。 4）跳出授权界面，正常填写树莓派用户名和密码即可。 5）点击ok即可进入界面。 6）另外还需设置一下分辨率，终端输入命令 1sudo vim /boot/config.txt 找到如下两行，将其设置为自己电脑的分辨率即可。比如我的电脑是1920x1080。 12framebuffer_width=1920framebuffer_width=1080 7）重启就可以像自己笔记本一样正常显示了。 4. TeamViewer TeamViewer 是一款可以实现远程桌面共享与文件传输的软件。它发挥作用的前提是主机和远程主机不需要在同一网段内！比如，下图是我用该软件来在本地共享树莓派桌面。 PC端和树莓派的teamviewer版本要一致，不然不能连接哦！这里Windows电脑使用的是TeamViewer14，故在树莓派也要实用14版本。 1）下载Teamviewer 使用SecureFx将在官网下载好的teamviewer-host_14.2.8352_armhf.deb改名为teamviewer-host_armhf.deb拷贝到树莓派/home/pi目录下。 然后在终端执行下面两条命令。 123sudo dpkg -i teamviewer-host_armhf.debsudo apt-get -f install 2）安装GDebi，解决依赖问题 1sudo apt-get install gdebi 3）安装Teamviewer 1sudo gdebi teamviewer-host_armhf.deb 4）常用命令，建议第一次安装好TeamViewer就设置。 123456teamviewer help #查看帮助信息teamviewer info #查看本机IDsudo teamviewer passwd [你的密码] #设置本机密码sudo teamviewer --daemon start #启动TeamViewer服务sudo teamviewer --daemon enable #开启TeamViewer服务随机启动sudo reboot #重启即可连接 以上常用命令使每次接通树莓派电源，就自启动TeamViewer，然后通过Windows端控制，一劳永逸。 5）在PC端输入伙伴ID、连接、输入teamviewer密码 伙伴ID由刚刚的teamviewer info命令获取； 密码由刚刚的sudo teamviewer passwd [你的密码]命令自己设置的。 6）更改树莓派的分辨率 由于刚刚已经在VNC Viewer设置过，这里就不需要了。 介绍了炒鸡好用的软件，那么问题来了，怎么样能以最快的速度下载安装好这些软件呢？ 公众号后台回复“远程连接”即可获得百度云链接。 然后就可以开始你的远程连接工作啦，还不快去试试！]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Win10</tag>
        <tag>SecureCRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图片标注工具LabelImg使用教程]]></title>
    <url>%2F2019%2F04%2F17%2F%E5%9B%BE%E7%89%87%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7LabelImg%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言 我们知道，图片标注主要是用来创建自己的数据集，方便进行深度学习训练。本篇博客将推荐一款十分好用的图片标注工具LabelImg，重点介绍其安装以及使用的过程。 正文 这款工具是全图形界面，用Python和Qt写的，最牛的是其标注信息可以直接转化成为XML文件，与PASCAL VOC以及ImageNet用的XML是一样的。 1.安装1.1 下载源码并运行项目地址:LabelImg 下载源码压缩包，解压可得到名为labelImg-master的文件夹，进入该文件夹，在空白处使用“Shift+鼠标右键”，进入当前目录的命令行窗口（PowerShell），依次输入下面语句即可打开软件。 12pyrcc5 -o resources.py resources.qrcpython labelImg.py 结果： 注意：上述代码成功运行的条件是电脑安装anaconda以及安装好pyqt5库。 1.2 运行打包文件百度云备份：windows_v1.3.4 密码: r7yh 无需编译，直接打开就能用！ 将百度云文件保存并下载到本地，运行目录工具/labelImg.exe即可出现1.1下载源码并运行 所示结果。 2.使用1）点击Open Dir，然后点击刚刚保存在F盘的文件夹Images/001，图片路径就会出现在右下角位置。 2）点击Create RectBox，然后在图上将交通标志框选出来。然后输入类别（一共三类）： （1）禁止标志（Prohibitory）：红色、圆形； （2）强制性标志（Mandatory）：蓝色、圆形； （3）危险标志（Danger）：黄色、三角形； 输入对应类别英文，然后点击OK。注意，有的图片不止一个交通标志，都需要标记出来。 3）然后点击Save，默认保存.xml文件即可。 4）然后点击下一张，重复操作即可。 3.注意1）xml文件也是可以用文本文档打开的。 文件包里面还提供了一个GroundTruth.csv文件，可以验证自己的标注（上图划红线部分，只要两份数据相近即可）。 2）标注过程中可随时返回进行修改，后保存的文件会覆盖之前的。 3）有时候，下载的图片集不是jpg格式，这个时候就需要转换工具。文件夹工具提供了这样一个工具，将目录工具/convert.bat拷贝到图片集，双击即可实现将所有的png文件转为jpg文件。 后文 其他同类标注工具（Github）：1）Yolo_mark2）BBox-Label-Tool3）ImageLabel]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>LabelImg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶环境感知--基于Keras的车辆实时检测]]></title>
    <url>%2F2019%2F03%2F28%2F%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%84%9F%E7%9F%A5--%E5%9F%BA%E4%BA%8EKeras%E7%9A%84%E8%BD%A6%E8%BE%86%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[前言 ​ 车辆是行驶环境中的目标检测之一，其他的还有车道线检测、交通信号灯、交通标志检测。它是无人驾驶感知的重要一环。本文基于深度学习框架Keras完成数据集的训练与测试，达到识别车辆的效果。本文适合于对深度学习有一定了解，最好用过深度学习框架的童鞋。 正文 0.导入库1234567891011import numpy as npimport matplotlib.pyplot as pltimport cv2import globfrom moviepy.editor import VideoFileClipimport keras # use 2.0.8from keras.models import Sequentialfrom keras.layers.convolutional import Convolution2D, MaxPooling2Dfrom keras.layers.advanced_activations import LeakyReLUfrom keras.layers.core import Flatten, Dense, Activation, Reshapefrom utils import load_weights,Box,yolo_net_out_to_car_boxes, draw_box 1.Fast YOLO网络结构功能：原来YOLO整个网络结构包含了24个卷积层以及2个全连接层。由于车辆检测对实时性要求高，我们使用一种YOLO的简化版本：Fast YOLO，该模型使用简单的9层卷积替代了原来的24层卷积，它牺牲了一定的精度，处理速度更快，从YOLO的45fps提升到155fps。满足实时目标检测的需求。 （原YOLO网络结构） 1.1 修改图片通道顺序代码： 12#图片通道顺序修改为(channels,,height,width),保持和input_shape一致。keras.backend.set_image_dim_ordering('th') 1.2 自定义网络结构（Fast YOLO）代码： 12345678910111213141516171819202122232425262728293031#在这里，网络的输入变成了 448×448 ， 输出是一个 7×7×30 的张量。model = Sequential()model.add(Convolution2D(16, (3, 3),input_shape=(3,448,448),padding='same',strides=(1,1)))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Convolution2D(32, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))model.add(Convolution2D(64, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))model.add(Convolution2D(128, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))model.add(Convolution2D(256, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))model.add(Convolution2D(512, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))model.add(Convolution2D(1024, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(Convolution2D(1024, (3, 3),padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(Convolution2D(1024, (3, 3) ,padding='same'))model.add(LeakyReLU(alpha=0.1))model.add(Flatten())model.add(Dense(256))model.add(Dense(4096))model.add(LeakyReLU(alpha=0.1))model.add(Dense(1470)) 1.3模型可视化代码： 1model.summary() 打印： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465_________________________________________________________________Layer (type) Output Shape Param # =================================================================conv2d_318 (Conv2D) (None, 16, 448, 448) 448 _________________________________________________________________leaky_re_lu_353 (LeakyReLU) (None, 16, 448, 448) 0 _________________________________________________________________max_pooling2d_213 (MaxPoolin (None, 16, 224, 224) 0 _________________________________________________________________conv2d_319 (Conv2D) (None, 32, 224, 224) 4640 _________________________________________________________________leaky_re_lu_354 (LeakyReLU) (None, 32, 224, 224) 0 _________________________________________________________________max_pooling2d_214 (MaxPoolin (None, 32, 112, 112) 0 _________________________________________________________________conv2d_320 (Conv2D) (None, 64, 112, 112) 18496 _________________________________________________________________leaky_re_lu_355 (LeakyReLU) (None, 64, 112, 112) 0 _________________________________________________________________max_pooling2d_215 (MaxPoolin (None, 64, 56, 56) 0 _________________________________________________________________conv2d_321 (Conv2D) (None, 128, 56, 56) 73856 _________________________________________________________________leaky_re_lu_356 (LeakyReLU) (None, 128, 56, 56) 0 _________________________________________________________________max_pooling2d_216 (MaxPoolin (None, 128, 28, 28) 0 _________________________________________________________________conv2d_322 (Conv2D) (None, 256, 28, 28) 295168 _________________________________________________________________leaky_re_lu_357 (LeakyReLU) (None, 256, 28, 28) 0 _________________________________________________________________max_pooling2d_217 (MaxPoolin (None, 256, 14, 14) 0 _________________________________________________________________conv2d_323 (Conv2D) (None, 512, 14, 14) 1180160 _________________________________________________________________leaky_re_lu_358 (LeakyReLU) (None, 512, 14, 14) 0 _________________________________________________________________max_pooling2d_218 (MaxPoolin (None, 512, 7, 7) 0 _________________________________________________________________conv2d_324 (Conv2D) (None, 1024, 7, 7) 4719616 _________________________________________________________________leaky_re_lu_359 (LeakyReLU) (None, 1024, 7, 7) 0 _________________________________________________________________conv2d_325 (Conv2D) (None, 1024, 7, 7) 9438208 _________________________________________________________________leaky_re_lu_360 (LeakyReLU) (None, 1024, 7, 7) 0 _________________________________________________________________conv2d_326 (Conv2D) (None, 1024, 7, 7) 9438208 _________________________________________________________________leaky_re_lu_361 (LeakyReLU) (None, 1024, 7, 7) 0 _________________________________________________________________flatten_36 (Flatten) (None, 50176) 0 _________________________________________________________________dense_106 (Dense) (None, 256) 12845312 _________________________________________________________________dense_107 (Dense) (None, 4096) 1052672 _________________________________________________________________leaky_re_lu_362 (LeakyReLU) (None, 4096) 0 _________________________________________________________________dense_108 (Dense) (None, 1470) 6022590 =================================================================Total params: 45,089,374Trainable params: 45,089,374Non-trainable params: 0_________________________________________________________________ 2.加载模型数据功能：使用已经训练好的模型，将模型参数加载到keras模型中 代码： 1load_weights(model,'yolo-tiny.weights') 注意：原YOLO整个网络包含了24个卷积层以及2个全连接层。 3.将模型用于测试单张图片3.1主程序代码： 123456789101112131415161718192021222324252627282930313233343536373839404142#加载图片imagePath = 'test_images/test1.jpg'image = plt.imread(imagePath)print("image:" + str(image.shape))##图片预处理#裁剪图片image_crop = image[300:650,500:,:]#重置尺寸448*448resized = cv2.resize(image_crop,(448,448))print("resized:" + str(resized.shape))#转置#shape：(448, 448, 3)-&gt;(3, 448, 448)batch = np.transpose(resized,(2,0,1))print("np.transpose:" + str(batch.shape))#print(batch)#将像素点取值区间从[0~255]过渡到[-1~1]batch = 2*(batch/255.) - 1#print(batch)print("batch:" + str(batch.shape))#增加一个维度#[批量大小，通道, 高度，宽度] batch = np.expand_dims(batch, axis=0)print("np.expand_dims" + str(batch.shape))#输入到YOLO网络#输出预测为每一类的置信概率，一共1470类。out = model.predict(batch)print("out:" + str(out.shape))#从YOLO网络的输出中提取出车辆的检测结果#调用yolo_net_out_to_car_boxes（）函数进行测试boxes = yolo_net_out_to_car_boxes(out[0], threshold = 0.17)#可视化结果f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,6))ax1.imshow(image)#调用draw_box（）函数画框图ax2.imshow(draw_box(boxes,plt.imread(imagePath),[[500,1280],[300,650]])) 打印： 123456image:(720, 1280, 3)resized:(448, 448, 3)np.transpose:(3, 448, 448)batch:(3, 448, 448)np.expand_dims(1, 3, 448, 448)out:(1, 1470) 注意： 批量梯度下降法（Batch Gradient Descent） ：在更新参数时都使用所有的样本来进行更新。 优点：全局最优解，能保证每一次更新权值，都能降低损失函数；易于并行实现。 缺点：当样本数目很多时，训练过程会很慢。 随机梯度下降法（Stochastic Gradient Descent）：在更新参数时都使用一个样本来进行更新。每一次跟新参数都用一个样本，更新很多次。如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将参数迭代到最优解了，对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次，这种方式计算复杂度太高。 优点：训练速度快； 缺点：准确度下降，并不是全局最优；不易于并行实现。从迭代的次数上来看，随机梯度下降法迭代的次数较多，在解空间的搜索过程看起来很盲目。噪音很多，使得它并不是每次迭代都向着整体最优化方向。 小批量梯度下降法（Mini-batch Gradient Descen）：在更新每一参数时都使用一部分样本来进行更新。为了克服上面两种方法的缺点，又同时兼顾两种方法的优点。 三种方法使用的情况：如果样本量比较小，采用批量梯度下降算法。如果样本太大，或者在线算法，使用随机梯度下降算法。在实际的一般情况下，采用小批量梯度下降算法。 3.2yolo_net_out_to_car_boxes()函数代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#S:7*7个网格#C:每个网格含20个目标类别信息#B:每个网格含2个bounding box，每个bounding box含5个信息#1470 = 7*7*30 =7*7*10 + 7*7*20 = 7*7*2*5 + 7*7*20def yolo_net_out_to_car_boxes(net_out, threshold=0.2, sqrt=1.8, C=20, B=2, S=7): ##定义参数 class_num = 6 boxes = [] SS = S * S #网格单元数 prob_size = SS * C #类别信息尺寸 conf_size = SS * B #网格包含2个bounding box中的信息尺寸 #列表 probs = net_out[0: prob_size]#类别信息 confs = net_out[prob_size: (prob_size + conf_size)]#置信度 cords = net_out[(prob_size + conf_size):] #(x,y,w,h) #列表转矩阵 probs = probs.reshape([SS, C]) confs = confs.reshape([SS, B]) cords = cords.reshape([SS, B, 4]) ##测试 #对整个图像的每个网格都做这种操作，则可以得到 7×7×2=987×7×2=98 个bounding box， #这些bounding box既包含坐标等信息也包含类别信息。 for grid in range(SS):#遍历7*7的每个网格 for b in range(B):#遍历2个bounding box bx = Box()#将类Box实例化 bx.c = confs[grid, b]#置信度（confidence）：代表了所预测的box中含有object的置信度和这个box预测的有多准两重信息 bx.x = (cords[grid, b, 0] + grid % S) / S#中心坐标 (x,y),即我们要预测的目标的所在的矩形区域的中心的坐标值。 bx.y = (cords[grid, b, 1] + grid // S) / S bx.w = cords[grid, b, 2] ** sqrt#bounding box的宽和高 (w,h) bx.h = cords[grid, b, 3] ** sqrt p = probs[grid, :] * bx.c#类别置信度得分 #设置阈值，滤掉得分低的boxes if p[class_num] &gt;= threshold: bx.prob = p[class_num] boxes.append(bx) #进行NMS（Non-maximum suppression）:非最大抑制处理。 #首先基于物体检测分数产生检测框，分数最高的检测框M被选中， #其他与被选中检测框有明显重叠的检测框被抑制 #boxes = [(c1,x1,y1,w1,h1,prob1),(c2,x2,y2,w2,h2,prob2)...] boxes.sort(key=lambda b: b.prob, reverse=True)#按关键词prob从大到小排序 for i in range(len(boxes)): boxi = boxes[i] #bounding box if boxi.prob == 0: continue #检测分数为0，不会产生检测框，跳出本次循环 for j in range(i + 1, len(boxes)): boxj = boxes[j]#其他bounding box if box_iou(boxi, boxj) &gt;= .4:#boxi与boxj重叠部分大于阈值0.4 boxes[j].prob = 0.#将boxj移除 boxes = [b for b in boxes if b.prob &gt; 0.]#再次筛选（移除b.prob为负值的部分） return boxes 注意1： 网络的输出 7×7×30 负责这7*7个网格的回归预测。我们来看看这每个网格的30个输出构成： 每个网格都要预测2个bounding box，bounding box即我们用来圈出目标的矩形（也就是目标所在的一个矩形区域），一个bounding box包含如下信息： 中心坐标 (x,y) 即我们要预测的目标的所在的矩形区域的中心的坐标值。 (w,h) 即bounding box的宽和高 置信度（confidence）：代表了所预测的box中含有object的置信度和这个box预测的有多准两重信息 每个网格都要预测两个bounding box，即10个输出，此外，还有20个输出代表目标的类别，YOLO论文在训练时一共检测20类物体，所以一共有20个类别的输出,我们记做 C，合集每个网格的预测输出有30个数值。 注意2： 在测试阶段，每个网格预测的类别信息和bounding box预测的confidence相乘，就得到每个bounding box的class-specific confidence score。那么对整个图像的每个网格都做这种操作，则可以得到 7×7×2=98个bounding box，这些bounding box既包含坐标等信息也包含类别信息。 得到每个bounding box的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果。 NMS（Non-maximum suppression）:非最大抑制，它首先基于物体检测分数产生检测框，分数最高的检测框M被选中，其他与被选中检测框有明显重叠的检测框被抑制。在本例中，使用YOLO网络预测出一系列带分数的预选框，当选中最大分数的检测框M，它被从集合B中移出并放入最终检测结果集合D。于此同时，集合B中任何与检测框M的重叠部分大于重叠阈值Nt的检测框也将随之移除。 3.3 draw_box()函数1234567891011121314151617181920212223242526def draw_box(boxes, im, crop_dim): imgcv = im #数学推导 [xmin, xmax] = crop_dim[0] [ymin, ymax] = crop_dim[1] for b in boxes: h, w, _ = imgcv.shape left = int((b.x - b.w / 2.) * w) right = int((b.x + b.w / 2.) * w) top = int((b.y - b.h / 2.) * h) bot = int((b.y + b.h / 2.) * h) left = int(left * (xmax - xmin) / w + xmin) right = int(right * (xmax - xmin) / w + xmin) top = int(top * (ymax - ymin) / h + ymin) bot = int(bot * (ymax - ymin) / h + ymin) if left &lt; 0: left = 0 if right &gt; w - 1: right = w - 1 if top &lt; 0: top = 0 if bot &gt; h - 1: bot = h - 1 thick = int((h + w) // 150) #cv2.rectangle（图片，（左，左上），（右，右上），颜色，粗细） cv2.rectangle(imgcv, (left, top), (right, bot), (255, 0, 0), thick) return imgcv 4.将模型用于测试图片集代码： 12345678910111213#读取test_images里面所有的图片images = [plt.imread(file) for file in glob.glob('test_images/*.jpg')]batch = np.array([np.transpose(cv2.resize(image[300:650,500:,:],(448,448)),(2,0,1)) for image in images])batch = 2*(batch/255.) - 1print("batch:" + str(batch.shape))out = model.predict(batch)#可视化结果f,((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize=(11,10))for i,ax in zip(range(len(batch)),[ax1,ax2,ax3,ax4,ax5,ax6]): boxes = yolo_net_out_to_car_boxes(out[i], threshold = 0.17) ax.imshow(draw_box(boxes,images[i],[[500,1280],[300,650]])) 打印： 1batch:(6, 3, 448, 448) 注意：代码基本是步骤3的重复。 5.将模型用于视频123456789101112131415161718#处理方法同图片def frame_func(image): crop = image[300:650,500:,:] resized = cv2.resize(crop,(448,448)) batch = np.array([resized[:,:,0],resized[:,:,1],resized[:,:,2]]) batch = 2*(batch/255.) - 1 batch = np.expand_dims(batch, axis=0) out = model.predict(batch) boxes = yolo_net_out_to_car_boxes(out[0], threshold = 0.17) return draw_box(boxes,image,[[500,1280],[300,650]])vedio_in = VideoFileClip("video_in/test01.mp4")#读取文件夹video_in视频video_out = 'video_out/test01_out.mp4'#保存视频到文件夹video_inlane_clip = vedio_in.fl_image(frame_func) #将视频以图片帧的形式传递给frame_func()函数lane_clip.write_videofile(video_out, audio=False)#重新合成视频 打印： 注意： 视频本质上还是图片 代码基本是步骤3的重复 加入视频转换成图片以及图片合成视频步骤。 以上。]]></content>
      <categories>
        <category>无人驾驶环境感知</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Keras</tag>
        <tag>车辆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶环境感知--基于HSV色彩空间的交通信号灯识别（0.97）]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%84%9F%E7%9F%A5--%E5%9F%BA%E4%BA%8EHSV%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BF%A1%E5%8F%B7%E7%81%AF%E8%AF%86%E5%88%AB%EF%BC%880.97%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言 交通信号灯是行驶环境中的目标检测之一，其他的还有车道线检测、车辆检测、交通标志检测。它是无人驾驶感知的重要一环。本文是基于特征检测完成数据集的训练与测试，达到识别交通信号灯的目的。目前准确率为0.975。 正文 0.导入库1234567import cv2 import helpers import test_functionsimport randomimport numpy as npimport matplotlib.pyplot as pltimport matplotlib.image as mpimg 1.加载交通信号灯数据集代码： 12345678##1.加载交通信号灯数据集# 图像集目录IMAGE_DIR_TRAINING = "traffic_light_images/train"IMAGE_DIR_TEST = "traffic_light_images/test"#使用helpers.py文件中的load_dataset函数加载图像IMAGE_LIST = helpers.load_dataset(IMAGE_DIR_TRAINING)print("训练集照片总数：" + str(len(IMAGE_LIST))) 注意： load_dataset（）函数代码： 123456789101112131415161718192021222324252627def load_dataset(image_dir): im_list = [] image_types = [ "red", "yellow", "green"] print("红、黄、绿照片的数量分别为：") # 遍历每个颜色类型文件夹 for im_type in image_types: # 遍历每个image_type文件夹中的每个图像文件 #获取指定目录下（traffic_light_images/train/red(yellow)(green)）的所有图片 file_lists = glob.glob(os.path.join(image_dir, im_type, "*")) #分别打印红、黄、绿照片的数量 print(len(file_lists)) for file in file_lists: im = mpimg.imread(file)# 读取图片 # 检查图片是否存在以及是否被正确读取 if not im is None: #在列表中加入图片以及该图所属的类型 im_list.append((im, im_type)) return im_list 打印： 12345红、黄、绿照片的数量分别为：72335429训练集照片总数：1187 注意： 12im_list[500][0]#表示第500张图片im_list[500][1]#表示第500张图片的标签 2.将数据集可视化功能：由上述可知，红色共有723张，黄色共有35张，绿色共有429张。所以可选择500,750,1000做可视化。 代码： 1234567891011121314151617181920212223##2.将数据集可视化# 红：723；黄：35 绿：429；#显示图像#打印图片的尺寸和标签_,ax = plt.subplots(1,3,figsize=(5,2)) #新建red_image = IMAGE_LIST[500][0] #红灯ax[0].set_title(red_image.shape,fontsize=10) #标题--图片形状ax[0].annotate(IMAGE_LIST[500][1],xy=(2,5),color='blue',fontsize='10') #标记--蓝色标签ax[0].axis('off')#省去坐标轴ax[0].imshow(red_image)yellow_image = IMAGE_LIST[750][0]ax[1].set_title(yellow_image.shape,fontsize=10)ax[1].annotate(IMAGE_LIST[750][1],xy=(2,5),color='blue',fontsize='10')ax[1].axis('off')ax[1].imshow(yellow_image)green_image = IMAGE_LIST[1000][0]ax[2].set_title(green_image.shape,fontsize=10)ax[2].annotate(IMAGE_LIST[1000][1],xy=(2,5),color='blue',fontsize='10')ax[2].axis('off')ax[2].imshow(green_image)plt.show() 打印： 注意：在matplotlib中，整个图像为一个Figure对象。在Figure对象中可以包含一个或者多个Axes对象。每个Axes(ax)对象都是一个拥有自己坐标系统的绘图区域。上面代码中创建了三个ax对象并有自己的坐标，最后这三个对象可以保存成一张图片。 3.预处理数据代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546##3. 预处理数据##标准化输入及输出##输入#将每张图图片的大小resize成相同的大小，因为对于分类任务来说，我们需要在每张图片上应用相同的算法，因此标准化图像尤其重要def standardize_input(image): standard_im = cv2.resize(image,(32,32)) return standard_im##输出#这里我们的标签数据是类别数据：’red’,’yellow’,’green’，因此我们可以利用one_hot方法将类别数据转换成数值数据#红灯的数值数据应该是：[1,0,0]，黄灯应该是：[0，1，0]，绿灯应该是：[0，0，1]。这些标签被称为独热编码标签。def one_hot_encode(label): if label == "red": return [1,0,0] elif label == "yellow": return [0,1,0] else: return [0,0,1]#构建一个输入RGB图像列表：图像加类型数据#并输出标准化图像列表：图像和数值数据def standardize(image_list): standard_list = [] #遍历 for item in image_list: image = item[0] label = item[1] # 调用standardize_input函数 standardized_im = standardize_input(image) # 调用one_hot_encode函数 one_hot_label = one_hot_encode(label) #加入到新的standard_list列表中 standard_list.append((standardized_im, one_hot_label)) return standard_list#标准化所有的训练图片Standardized_Train_List = standardize(IMAGE_LIST) 4.将标准化数据可视化功能：将第1100张图片经过标准化和独热编码预处理。 代码： 123456789##4.将标准化数据可视化# 红：723；黄：35 绿：429；num = 1100standard_image = Standardized_Train_List[num][0]plt.title(standard_image.shape)plt.annotate('Label [red, yellow, green]:'+ str(Standardized_Train_List[num][1]),xy=(2,5),color='blue',fontsize='12')plt.axis('off')plt.imshow(standard_image)plt.show() 打印： 5.特征提取（全文重点）功能：这里主要是先将图片从RGB域变换到HSV域，然后处理图片使图片分别变成只有红色、绿色、黄色。然后再统计图片像素点，最后根据具备某特征像素点数比较大小确定结果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778##5. 特征提取#HSV即色相、饱和度、明度（英语：Hue, Saturation, Value），又称HSB，其中B即英语：Brightness。#色相（H）是色彩的基本属性，就是平常所说的颜色名称，如红色、黄色等。#饱和度（S）是指色彩的纯度，越高色彩越纯，低则逐渐变灰，取0-100%的数值。#明度（V），亮度（L），取0-100%。#在这里我们将使用色彩空间、形状分析及特征构造def estimate_label(rgb_image,display): ''' 使用hsv和经验阈值来确定每个图像中的红色、绿色和黄色内容。 返回基于独热标签的的分类。 ''' hsv = cv2.cvtColor(rgb_image,cv2.COLOR_RGB2HSV)#REB域转HSV域 sum_saturation = np.sum(hsv[:,:,1])# 将明度值相加 area = 32*32 avg_saturation = sum_saturation / area #求平均的明度值 #设定阈值 sat_low = int(avg_saturation*1.3)#均值的1.3倍，工程经验 val_low = 140 ##过滤图像使图像只有绿色或黄色或白色(正常红绿灯为白色或者黄色) #在车道线检测里面提过，类似于PhotoShop里面的蒙版 #Green lower_green = np.array([70,sat_low,val_low]) upper_green = np.array([100,255,255]) green_mask = cv2.inRange(hsv,lower_green,upper_green) green_result = cv2.bitwise_and(rgb_image,rgb_image,mask = green_mask) #Yellow lower_yellow = np.array([10,sat_low,val_low]) upper_yellow = np.array([60,255,255]) yellow_mask = cv2.inRange(hsv,lower_yellow,upper_yellow) yellow_result = cv2.bitwise_and(rgb_image,rgb_image,mask=yellow_mask) # Red lower_red = np.array([150,sat_low,val_low]) upper_red = np.array([180,255,255]) red_mask = cv2.inRange(hsv,lower_red,upper_red) red_result = cv2.bitwise_and(rgb_image,rgb_image,mask = red_mask) #可视化图片于画布上 if display==True: _,ax = plt.subplots(1,5,figsize=(20,10)) ax[0].set_title('rgb image') ax[0].imshow(rgb_image) ax[1].set_title('red result') ax[1].imshow(red_result) ax[2].set_title('yellow result') ax[2].imshow(yellow_result) ax[3].set_title('green result') ax[3].imshow(green_result) ax[4].set_title('hsv image') ax[4].imshow(hsv) plt.show() sum_green = findNoneZero(green_result) sum_red = findNoneZero(red_result) sum_yellow = findNoneZero(yellow_result) #分析返回的像素点数 if sum_red &gt;= sum_yellow and sum_red&gt;=sum_green: return [1,0,0]#Red if sum_yellow&gt;=sum_green: return [0,1,0]#yellow return [0,0,1]#green#遍历一个一个像素点def findNoneZero(rgb_image): rows,cols,_= rgb_image.shape counter = 0 for row in range(rows): for col in range(cols): pixels = rgb_image[row,col] if sum(pixels)!=0: counter = counter+1 return counter 6.用照片测试提取的特征功能：这里用上文可视化过的三张图片来测试。 12345678##6.用照片测试提取的特征img_test = [(red_image,'red'),(yellow_image,'yellow'),(green_image,'green')]standardtest = standardize(img_test)for img in standardtest: predicted_label = estimate_label(img[0],display = True) print('Predict label :',predicted_label) #预测标签 print('True label:',img[1])#真实标签 打印: 12Predict label : [1, 0, 0]True label: [1, 0, 0] 12Predict label : [0, 1, 0]True label: [0, 1, 0] 12Predict label : [0, 0, 1]True label: [0, 0, 1] 7.测试数据集123456789101112131415161718192021##7.测试数据集#下载测试集TEST_IMAGE_LIST = helpers.load_dataset(IMAGE_DIR_TEST)print("测试集照片总数：" + str(len(TEST_IMAGE_LIST)))#标准化测试集STANDARDIZED_TEST_LIST = standardize(TEST_IMAGE_LIST)# shuffle() 方法将序列的所有元素随机排序。random.shuffle(STANDARDIZED_TEST_LIST) #调用get_misclassified_images()函数找出测试集中所有错误分类的图片MISCLASSIFIED = get_misclassified_images(STANDARDIZED_TEST_LIST,display=False) #计算准确率total = len(STANDARDIZED_TEST_LIST) #总的测试集数目num_correct = total - len(MISCLASSIFIED)#正确测试数目accuracy = num_correct/total #准确率 print('准确率: ' + str(accuracy))print("未正确分类图片数 = " + str(len(MISCLASSIFIED)) +' out of '+ str(total)) 打印： 1234561819107测试集照片总数：297准确率: 0.9797979797979798未正确分类图片数 = 6 out of 297 注意： 调用的get_misclassified_images()函数 12345678910111213141516171819#测试集准确率计算函数 def get_misclassified_images(test_images,display=False): misclassified_images_labels = [] for image in test_images: im = image[0] #测试图片 true_label = image[1] #真实图片标签 #预测图片标签 predicted_label = estimate_label(im,display=False) #比较真实和预测标签 if(predicted_label != true_label): #把错误标签添加到列表中 misclassified_images_labels.append((im, predicted_label, true_label)) return misclassified_images_labels 后文 在这个项目中，我们使用HSV色彩空间来识别交通灯，可以改善及提高的地方，以RCNN为代表的基于Region Proposal的深度学习目标检测算法以及以YOLO为代表的基于回归方法的深度学习目标检测算法。 即采用Faster-RCNN或SSD来实现交通灯的识别 然后将训练好的模型应用于图像和视频流。]]></content>
      <categories>
        <category>无人驾驶环境感知</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>交通信号灯</tag>
        <tag>特征检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于CMOS单目摄像头的人脸检测和移动物体检测]]></title>
    <url>%2F2019%2F03%2F25%2F%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E6%91%84%E5%83%8F%E5%A4%B4%E7%9A%84%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E7%A7%BB%E5%8A%A8%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[前言 生活中最常见的是电脑摄像头还有监视摄像头，以及购置的CMOS摄像头。本文正是在电脑和CMOS摄像头基础上实现人脸检测和移动物体检测。 正文 1. 人脸检测功能：打开摄像头，读取帧，检测帧中的人脸，扫描检测到的人脸中的眼睛，对人脸绘制蓝色的矩形框，对眼睛绘制绿色的矩形框，并实时追踪。（人丑没贴结果照片(T＿T)） 代码： 123456789101112131415161718192021222324252627282930313233343536373839import cv2def detect(): #获取Haar级联特征 face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_default.xml')#获取Haar级联数据 eye_cascade = cv2.CascadeClassifier('cascades/haarcascade_eye.xml') camera = cv2.VideoCapture(0) #打开摄像头，如果外接摄像头，更改参数为1即可。 while cv2.waitKey(27) == -1 : #发生条件为“Esc”键没有被按下 ret, frame = camera.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#灰度图像 #faces = face_cascade.detectMultiScale(gray, scaleFactor, minNeighbors) #scaleFactor:人脸检测过程中每次迭代时图像的压缩率 #minNeighbors：每个人脸矩形保留近邻数目的最小值 #返回值为人脸矩形数组 faces = face_cascade.detectMultiScale(gray, 1.3, 5) #绘制人脸方框 #x，y为左上角坐标，w和h表示人脸矩形的宽度和高度，（255，0，0）表示蓝色，2表示粗细 for (x,y,w,h) in faces: img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2) #设定区域为人脸方框，后面在这一片区域中绘制眼睛方框 roi_gray = gray[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray, 1.03, 5, 0, (40,40)) for (ex,ey,ew,eh) in eyes: cv2.rectangle(img,(x+ex,y+ey),(x+ex+ew,y+ey+eh),(0,255,0),2) cv2.imshow("Face Detection", frame) #显示摄像头帧窗口 camera.release() #释放摄像头 cv2.destroyAllWindows() #释放窗口 if __name__ == "__main__": detect() 注意： 类Haar特征是一种用于实现实时人脸跟踪的特征。 Haar级联具有尺度不变性，换句话说，它在尺度变化上具有鲁棒性。OpenCV提供了尺度不变Haar级联的分类器和追踪器，并可将其保存成指定的文件格式。 OpenCV的Haar级联不具有旋转不变性。所以在检测时，要获得最好的效果，我们需要正对着摄像头。 如果没有效果，需要摘掉眼镜。 2. 移动物体检测功能：打开摄像头（视频流），读取帧，检测帧中的移动物体，并对移动的物体绘制方框，并实时追踪。（人丑没贴结果照片(T＿T)） 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import cv2import numpy as npcamera = cv2.VideoCapture("vedio_in/traffic.flv")#加载视频流#camera = cv2.VideoCapture(0)#加载摄像头history = 20#设置20帧作为影响背景模型的帧 bs = cv2.createBackgroundSubtractorKNN(detectShadows = True) #初始化KNN背景分割器 bs.setHistory(history)frames = 0#帧计数器while cv2.waitKey(27) == -1: ret, frame = camera.read()#read（）解码并返回下一帧，ret判断视频帧是否成功读入，frame为实际读入的图像数组 #用BackgroundSubtractorKNN来构建背景模型的历史 fgmask = bs.apply(frame)#前景掩膜 # this is just to let the background subtractor build a bit of history if frames &lt; history: frames += 1 continue ##通过对前景掩膜采用膨胀和腐蚀的方法来识别斑点及周围边框 #二值化，将像素（127~255之间的像素都设为0） th = cv2.threshold(fgmask.copy(), 127, 255, cv2.THRESH_BINARY)[1] #cv2.getStructuringElement定义结构元素 #cv2.erode腐蚀 th = cv2.erode(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2) #cv2.dilate膨胀 dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,3)), iterations = 2) #轮廓检测 #cv2.RETR_EXTERNAL得到最外面的轮廓，这对消除包含在其他轮廓中的轮廓很有用 #cv2.CHAIN_APPROX_SIMPLE压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需4个点来保存轮廓信息 #cv2.findContours()函数返回两个值，一个是轮廓本身，还有一个是每条轮廓对应的属性。 contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) for c in contours: if cv2.contourArea(c) &gt; 500: #轮廓面积 (x,y,w,h) = cv2.boundingRect(c)#x，y是矩阵左上点的坐标，w，h是矩阵的宽和高 #第二个参数：（x，y）是矩阵的左上点坐标 #第三个参数：（x+w，y+h）是矩阵的右下点坐标 cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255), 1) #cv2.imshow("mog", fgmask) #cv2.imshow("thresh", th) #cv2.imshow("diff", frame &amp; cv2.cvtColor(fgmask, cv2.COLOR_GRAY2BGR)) cv2.imshow("detection", frame) #显示摄像头帧窗口camera.release()#释放摄像头cv2.destroyAllWindows()#释放窗口 注意： OpenCV提供了一个称为BackgroundSubtractor类，在分割背景和前景时很方便。 BackgroundSubtractor是一个功能很完全的类，该类不仅能执行背景分割，而且能够通过机器学习的方法提高背景检测效果，并提供将分来结果保存到文件的功能。 本程序是基于KNN背景分割器。 本程序基于分割前景和背景的差异，所以摄像头捕捉不到面部眼睛、鼻子的动作。 另外，本程序仅限于摄像头静止的场景，无论是视频流（监控摄像头）还是实际摄像头（电脑）。 3.摄像头标定（延伸）相机标定（Camera Calibration） 通常是做计算机视觉的第一步，首先，为什么要做相机标定呢？因为我们通过相机镜头记录下的图像往往存在一定程度的失真，这种失真往往表现为 图像畸变。畸变分为两类： 径向畸变（radial distortion）:由于透镜的特性，光线容易在相机镜头的边缘出现较小或者较大幅度的弯曲，称之为径向畸变。这种畸变在普通廉价的镜头中表现更加明显，径向畸变主要包括桶形畸变和枕形畸变两种。 切向畸变（tangential distortion）：是由于透镜本身与相机传感器平面（成像平面）或图像平面不平行而产生的，这种情况多是由于透镜被粘贴到镜头模组上的安装偏差导致。 畸变（distortion） 是对直线投影（rectilinear projection）的一种偏移。简单来说直线投影是场景内的一条直线投影到图片上也保持为一条直线。那畸变简单来说就是一条直线投影到图片上不能保持为一条直线了，这是一种光学畸变（optical aberration） 标定相机通常使用棋盘图像。一般来说，使用相机在各个角度拍摄20张左右的棋盘图即可完成后面的标定工作。 3.1 求摄像头畸变系数,并持久化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import numpy as npimport cv2import globimport matplotlib.pyplot as pltimport pickle#1.求畸变系数,并持久化def calibrate_camera(cal_images_path, cal_save_path): # 准备对象点，比如 (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0) objp = np.zeros((6*9, 3), np.float32) objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2) # 数组存储所有图像中的对象点和图像点 objpoints = [] # 现实空间中的三维点 imgpoints = [] # 图像平面中的二维点 # 列出待校准图像 images = glob.glob(cal_images_path) draw_index = 0 #创建一张画布（方法三） fig1 = plt.figure(1, figsize=(16, 9)) # 浏览待校准图像列表并搜索棋盘角 for fname in images: img = cv2.imread(fname) image_size = (img.shape[1], img.shape[0]) #改变图片大小尺寸 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#转为灰度图像 # 找出棋盘图中的对角（即图片中黑白相对的点的坐标） ret, corners = cv2.findChessboardCorners(gray, (9, 6),None) # 如果找到，分别添加三维点和二维点 if ret == True: objpoints.append(objp) imgpoints.append(corners) #绘制角点 img = cv2.drawChessboardCorners(img, (9, 6), corners, ret) # 可视化 #显示4个绘画过角点的棋盘 draw_index = draw_index + 1 if draw_index &lt;= 9: plt.subplot(3, 3, draw_index) plt.imshow(img) plt.title(fname) #求得这个相机的畸变系数，在后面的所有图像的矫正都可以使用这一组系数来完成。 ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_size, None, None) plt.show() # 持久化成字典，可以将对象以文件的形式存放在磁盘上。 #类似于tensorflow里面的持久化，方便后面复用。 cal_para = &#123;&#125; cal_para["mtx"] = mtx cal_para["dist"] = dist pickle.dump(cal_para, open(cal_save_path, "wb")) calibrate_camera('cam_cal_in/calibration*.jpg', 'calibration_paraeters.pkl') 打印： 注意： 畸变参数（distortion parameters）一般能够由五个参数来采集，我们使用 D=(k1,k2,p1,p2,k3) 来表示。 k1，k2，k3 表示径向畸变参数； p1，p2 表示切向畸变参数； cv2.calibrateCamera()函数返回的就是畸变参数，在后面的所有图像的矫正都可以使用这一组参数来完成。 3.2 测试棋盘图片1234567891011121314151617181920212223242526#2.测试棋盘图片#加载保存的模型with open('calibration_paraeters.pkl', mode='rb') as f: dist_pickle = pickle.load(f) mtx = dist_pickle["mtx"] dist = dist_pickle["dist"]#图像失真校正，返回未失真的图像def cal_undistort(img, mtx, dist): undist = cv2.undistort(img, mtx, dist, None, mtx) return undist# 读取一张棋盘图片img = cv2.imread('cam_cal_in/calibration1.jpg')#调用cal_undistort()函数undistorted = cal_undistort(img, mtx, dist)#可视化矫正前后图片f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 9))f.tight_layout()ax1.imshow(img)ax1.set_title('Original Image', fontsize=18)ax2.imshow(undistorted)ax2.set_title('Undistorted Image', fontsize=18)plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)plt.show() 打印： 3.3 测试实际路况图片12345678910111213141516#3.测试实际路况图片#读取一张实际路况图片origin_img = cv2.imread('test_images/test1.jpg')#调用cal_undistort()函数test_img = cal_undistort(origin_img, mtx, dist)#可视化矫正前后图片（方法二）f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,8))f.tight_layout()ax1.imshow(cv2.cvtColor(origin_img, cv2.COLOR_BGR2RGB))ax1.set_title('Original Image', fontsize=18)ax2.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))ax2.set_title('Undistorted Image', fontsize=18)plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)plt.show() 打印： 我们发现经过标定以后，相机拍出来的图像更接近于真实情况，因失真造成的”扭曲的直线”也被纠正过来。 以上。]]></content>
      <categories>
        <category>小项目</category>
      </categories>
      <tags>
        <tag>单目摄像头</tag>
        <tag>人脸检测</tag>
        <tag>移动物体检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶环境感知--基于霍夫变换的车道线检测]]></title>
    <url>%2F2019%2F02%2F20%2F%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%84%9F%E7%9F%A5--%E5%9F%BA%E4%BA%8E%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2%E7%9A%84%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[前言车道线检测属于结构化道路检测，是无人驾驶感知的重要一环。本文是基于霍夫变换实现图片和视频流的车道线检测。经典的霍夫变换是侦测图片中的直线，之后，霍夫变换不仅能识别直线，也能够识别任何形状，常见的有圆形、椭圆形。 正文1.导入包123456import matplotlib.pyplot as pltimport matplotlib.image as mpingimport numpy as npimport cv2from moviepy.editor import VideoFileClipfrom pylab import axis 注意：如果没有对应的库，请自行pip安装。 2.可移植性最强的运行程序图片集检测代码： 123456789101112131415161718192021#图片检测 test_imgs = utils.get_images_by_dir('images_in') #读取路径images中所有的图片results=[]for img in test_imgs: res = image_input(img) #对每张图片分别进行处理 results.append(res) #每张处理后的图片依次放置到列表results中 count = 0for result in results: cv2.imwrite('images_out/%s.png' % str(count),result[:,:,::-1]) #每张图片依次保存到images_out文件夹中 count +=1 count = 0 for i in range(len(results)): plt.figure(figsize=(10,48)) #显示图片尺寸 plt.subplot(len(results),1,i+1) #len(results)行1列 plt.title('image_out %s' %str(count)) #标题 count +=1 axis('off') #不显示坐标轴 plt.imshow(results[i]) #显示 截图： utils.py代码： 123456789import osimport matplotlib.image as mping#读取指定路径下的所有图片def get_images_by_dir(dirname): img_names = os.listdir(dirname) img_paths = [dirname+'/'+img_name for img_name in img_names] imgs = [mping.imread(path) for path in img_paths] #用mping读取图片 return imgs 注意： 两段代码实现的功能是将文件夹images_in中的图片集分别进行处理（检测车道直线），然后保存到另一文件夹images_out中。 .py文件和images_in以及images_out在同一目录内。 有两种读图、存图的方式：cv2.imread，这种方式是以BGR格式图片读取的，显示的也是BGR格式，对应的用cv2.imwrite就可以保存成RGB格式。 另外一种是mping.imread，这种方式是以RGB格式图片读取的，显示的也是RGB格式。 所以如果显示或者保存RGB格式，就有可能需要用[:,:,::-1]将BGR格式转换成RGB格式。 打印： 视频流检测代码： 1234567#视频检测def annotated_video(input_file, output_file): video = VideoFileClip(input_file) #将输入视频文件分解为一帧一帧 annotated_video = video.fl_image(image_input) #对每一帧进行处理 annotated_video.write_videofile(output_file, audio=False) #合成输出视频文件，并且屏蔽声音 annotated_video("project_video.mp4","outputvideo07.mp4") 输入输出视频文件 打印： 1234567pygame 1.9.4Hello from the pygame community. https://www.pygame.org/contribute.htmlMoviepy - Building video outputvideo07.mp4.Moviepy - Writing video outputvideo07.mp4Moviepy - Done !Moviepy - video ready outputvideo07.mp4 注意：视频的本质还是图像帧。 3.主程序代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#主函数def main(image_in): print("原始图片尺寸：" + str(image_in.shape)) image = filter_colors(image_in) #filter_colors()函数 #print("filter_colors: "+str(image.shape)) #plt.imshow(image) gray = grayscale(image) #grayscale()函数 #print("grayscale: "+str(gray.shape)) #plt.imshow(gray) blur_gray = gaussian_blur(gray, kernel_size) #gaussian_blur()函数 #print("gaussian_blur: "+str(blur_gray.shape)) #plt.imshow(blur_gray) edges = canny(blur_gray, low_threshold, high_threshold) #canny()函数 #print("canny: "+str(edges.shape)) #plt.imshow(edges) imshape = image.shape #(宽、长、通道数) '''rows, cols = image_in.shape[:2] bottom_left = [cols*0.1, rows*0.95] top_left = [cols*0.4, rows*0.6] bottom_right = [cols*0.9, rows*0.95] top_right = [cols*0.6, rows*0.6] vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32) print(vertices)''' vertices = np.array([[((imshape[1] * (1-trap_bottom_width)) // 2, imshape[0]),\ ((imshape[1] * (1-trap_top_width)) // 2, imshape[0] - imshape[0] * trap_height),\ (imshape[1]-(imshape[1] * (1-trap_top_width)) // 2, imshape[0] - imshape[0] * trap_height),\ (imshape[1]-(imshape[1] * (1-trap_bottom_width)) // 2, imshape[0])]]\ , dtype = np.int32) #四个坐标值确定感兴趣区域（梯形） masked_edges = region_of_interest(edges, vertices) #region_of_interest()函数 #print("region_of_interest:",masked_edges.shape) #plt.imshow(masked_edges) line_image = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap) #hough_lines()函数 #print("hough_lines:",line_image.shape) #plt.imshow(line_image) initial_image = image_in.astype('uint8') annotated_image = weighted_img(line_image, initial_image) #weighted_img()函数 #print("weighted_img:",annotated_image.shape) #plt.imshow(annotated_image) return annotated_image 打印： 12345678原始图片尺寸：(960, 1280, 3)filter_colors: (960, 1280, 3)grayscale: (960, 1280)gaussian_blur: (960, 1280)canny: (960, 1280)region_of_interest: (960, 1280)hough_lines: (960, 1280, 3)weighted_img: (960, 1280, 3) 注意： 主函数的输入是原始图片，输出是处理好的图片。其实就是整个图片的处理过程，不过中间调用多个子函数来实现对图片的一步步处理。 确定感兴趣区域 可能比较抽象，画图就好理解很多。 （感兴趣区域） 4.子函数4.1 定义全局变量功能：作为各个子函数中的参数。 1234567891011121314151617181920#设定所有参数kernel_size = 3#Canny边缘检测low_threshold = 50high_threshold = 120#感兴趣区域trap_bottom_width = 1 #百分比表达法trap_top_width = 0.3 # 同上 0.3合适trap_height = 0.41 #大部分合适0.41#霍夫变换rho = 1.0 #半径分辨率theta = 1 * np.pi/180 #角度分辨率threshold = 40 #大于此阈值的可当作线段min_line_length = 20 #指定线段最小长度 20大部分合适max_line_gap = 300 #间隙大于300则把两条线段当成一条线段， #值越大，允许线段上的断裂越大，越有可能检出潜在的直线段 4.2 各子函数注意： 各子函数打印图片为同一张图片。 4.2.1 filter_colors()函数代码： 1234567891011121314151617181920#过滤图像使图像只有白色和黄色(正常车道线为白色或者黄色)def filter_colors(img): #白色图象 white_threshold = 90 lower_white = np.uint8([0, white_threshold, 0]) upper_white = np.uint8([255, 255, 255]) #白色 white_mask = cv2.inRange(img , lower_white, upper_white) #lower_white~upper_white的范围值变为225，其他范围变为0 white_image = cv2.bitwise_and(img, img , mask=white_mask) #黄色图象 hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) #转换到HSV颜色空间 lower_yellow = np.uint8([10,0,100]) upper_yellow = np.uint8([40,255,255]) yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow) yellow_image = cv2.bitwise_and(img, img, mask=yellow_mask) #对两张图进行合成 image2 = cv2.addWeighted(white_image, 1., yellow_image, 1., 0.) #将两张图合在一起，1.和1.是两张图的权重 return image2 打印： 4.2.2 grayscale()函数代码： 123def grayscale(img): gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) return gray #转为灰度图像 打印： 4.2.3 gaussian_blur()函数功能： 高通滤波器是根据像素与邻近像素的亮度差值来提升该像素的亮度。 低通滤波器则是在像素与周围像素的亮度差值小于一个特定值时，平滑该像素的亮度。 主要用于去噪和模糊化，如高斯模糊是最常用的模糊滤波器，是一个削弱高频信号强度的低通滤波器。 代码： 12def gaussian_blur(img, kernel_size): return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0) #高斯模糊 打印： 4.2.4 canny()函数功能： 边缘在人类视觉和计算机视觉中起着重要作用。 OpenCV提供了许多边缘检测滤波函数，如Laplacian(), Sobel()以及Scharr()。 这些滤滤函数会将非边缘区域转为黑色，将边缘区域转为白色或其他饱和的颜色。 但它们又很容易将噪声错误地识别为边缘。解决方案就是在找到边缘之前对图像进行模糊处理。 代码： 12def canny(img, low_threshold, high_threshold): return cv2.Canny(img, low_threshold, high_threshold,kernel_size) #canny边缘检测 打印： 4.2.5 region_of_interest()函数功能： 感兴趣区域，就是我们从图像中选择一个图像区域，这个区域就是图像分析所关注的焦点。我们圈定这个区域，那么我们要处理的图像就从大图像变为一个小图像区域了，这样以便进行进一步处理，可以大大减小处理时间。 代码： 1234567891011121314151617def region_of_interest(img, vertices): mask = np.zeros_like(img) #定义一个和img维度一样大小的新矩阵（掩膜），初始化为全0 ，即全黑图像。 #根据输入图片来给掩膜填充3个或者1个颜色通道 if len(img.shape) &gt; 2: channel_count = img.shape[2] #通道数 ignore_mask_color = (255,) * channel_count else: ignore_mask_color = 255 #在全黑掩膜图像上填充“vertices”形状的图形，图形填充为白色。 cv2.fillPoly(mask, vertices, ignore_mask_color) #白色区域保留，黑色区域剔除（白显黑隐） masked_image = cv2.bitwise_and(img, mask) #（黑色，白色） return masked_image 打印： 注意： 事实上vertices即为所选取的感兴趣区域，注意上文对该段的解释。 感兴趣区域类似于photoshop里面的图层蒙版效果。 4.2.6 hough_lines()函数功能：在二值图像中查找直线。 代码： 12345678def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): lines = cv2.HoughLinesP(img, rho, theta, threshold, minLineLength=min_line_len, maxLineGap=max_line_gap) #霍夫变换 #print(lines)np.array([]), #print(img.shape) line_img = np.zeros((*img.shape, 3), dtype=np.uint8) #带一个星号（*）参数的函数传入的参数存储为一个元组（tuple） #plt.imshow(img) draw_lines(line_img, lines) #画线 return line_img 打印： 注意：各参数 image： 必须是二值图像，推荐使用canny边缘检测的结果图像 。 rho: 线段以像素为单位的距离精度，double类型的，推荐用1.0。 theta： 线段以弧度为单位的角度精度，推荐用np.pi/180。 threshod: 累加平面的阈值参数，int类型，超过设定阈值才被检测出线段，值越大，基本上意味着检出的线段越长，检出的线段个数越少。根据情况推荐先用100试试。 lines：这个参数的意义未知，发现不同的lines对结果没影响，但是不要忽略了它的存在 。 minLineLength：线段以像素为单位的最小长度，根据应用场景设置 。 maxLineGap：同一方向上两条线段判定为一条线段的最大允许间隔（断裂），超过了设定值，则把两条线段当成一条线段，值越大，允许线段上的断裂越大，越有可能检出潜在的直线段。 4.2.7draw_lines()函数功能：在所有直线中选取符合实际场景（车道线）的直线，这里采用的是平均斜率法，然后再标记出该直线。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899def draw_lines(img, lines, color=[255, 255, 0], thickness=15): if lines is None: return if len(lines) == 0: return draw_right = True draw_left = True ##找到所有直线的斜率 #只关心斜率绝对值大于阈值 slope_threshold = 0.5 #斜率阈值 slopes = [] #斜率 new_lines = [] #所有直线 for line in lines: x1, y1, x2, y2 = line[0] #计算斜率 if x2 - x1 == 0.: #避免除以0 slope = 999. else: slope = (y2 - y1) / (x2 - x1) if abs(slope) &gt; slope_threshold: slopes.append(slope) new_lines.append(line) lines = new_lines #所有直线 right_lines = [] #右车道所有直线 left_lines = [] #左车道所有直线 for i, line in enumerate(lines): x1, y1, x2, y2 = line[0] img_x_center = img.shape[1] / 2 #图片长度的一半 if slopes[i] &gt; 0 and x1 &gt; img_x_center and x2 &gt; img_x_center: right_lines.append(line) elif slopes[i] &lt; 0 and x1 &lt; img_x_center and x2 &lt; img_x_center: left_lines.append(line) ##运行线性回归找到最适合的车道线 #右车道 right_lines_x = [] right_lines_y = [] for line in right_lines: x1, y1, x2, y2 = line[0] right_lines_x.append(x1) right_lines_x.append(x2) right_lines_y.append(y1) right_lines_y.append(y2) #拟合得到右侧直线的斜率（right_m）和截距（right_b） if len(right_lines_x) &gt; 0: right_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1) #多项式拟合函数 y = m*x + b else: right_m, right_b = 1, 1 #自定义 draw_right = False #左车道 left_lines_x = [] left_lines_y = [] for line in left_lines: x1, y1, x2, y2 = line[0] left_lines_x.append(x1) left_lines_x.append(x2) left_lines_y.append(y1) left_lines_y.append(y2) #拟合得到左侧直线的斜率（left_m）和截距（left_b） if len(left_lines_x) &gt; 0: left_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1) else: left_m, left_b = 1, 1 draw_left = False #依据拟合的直线以及纵坐标求得横坐标 y1 = img.shape[0] y2 = img.shape[0] * (1-trap_height) right_x1 = (y1 - right_b) / right_m right_x2 = (y2 - right_b) / right_m left_x1 = (y1 - left_b) / left_m left_x2 = (y2 - left_b) / left_m #坐标值从float转化为 int y1 = int(y1) y2 = int(y2) right_x1 = int(right_x1) right_x2 = int(right_x2) left_x1 = int(left_x1) left_x2 = int(left_x2) #根据两侧的两个点坐标分别在图上划线，自定义颜色和线条粗细 if draw_right: cv2.line(img, (right_x1, y1), (right_x2, y2), color, thickness) if draw_left: cv2.line(img, (left_x1, y1), (left_x2, y2), color, thickness) 注意： ##找到所有直线的斜率 先通过斜率阈值筛选直线。 ##运行线性回归找到最适合的车道线。 然后利用已有的点拟合直线得到直线的斜率和截距，然后再利用已知的y坐标值求得对应的x坐标值，最后再利用（x，y）坐标值在原图上画线，即找到最合适的车道线。 直线表达式为y = m*x + b 4.2.8 weighted_img()函数代码： 12def weighted_img(img, initial_img, α=0.8, β=1.0, λ=0.): #将两张图合在一起，α和β是两张图的权重 return cv2.addWeighted(initial_img, α, img, β, λ) 打印： 注意：返回的是已经处理完的图片。 后记对于整张图而言，我们可以通过主函数和子函数这个角度来审视找到车道线的过程。 还可以通过范围搜索这个角度来审视。 第一步，感兴趣区域，缩小图片检索范围。 第二步，霍夫曼检测，检测所有直线（段）。 第三步，斜率阈值筛选，去除一部分直线（段）。 第四步，线性回归，找到最适合的直线（段）。]]></content>
      <categories>
        <category>无人驾驶环境感知</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>车道线</tag>
        <tag>霍夫变换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人驾驶环境感知--基于tensorflow的交通标志识别（0.96）]]></title>
    <url>%2F2019%2F02%2F08%2F%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%84%9F%E7%9F%A5--%E5%9F%BA%E4%BA%8Etensorflow%E7%9A%84%E4%BA%A4%E9%80%9A%E6%A0%87%E5%BF%97%E8%AF%86%E5%88%AB%EF%BC%880.96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言 ​ 交通标志是行驶环境中的目标检测之一，其他的还有车道线检测、车辆检测、交通标志检测。它是无人驾驶感知的重要一环。本文基于谷歌的深度学习框架tensorflow完成数据集的训练与测试，达到识别交通标志的效果。目前做到的准确率为0.96。本文适合于对深度学习有一定了解，最好用过深度学习框架的童鞋。 正文 1.导入库12345import utilimport pickleimport tensorflow as tffrom sklearn.utils import shufflefrom tensorflow.contrib.layers import flatten 注意：如果没有对应的库，请自行pip安装。 2.载入数据代码： 12345678910111213###载入数据training_file = 'data/train.p' #一种可以传输或存储的格式validation_file='data/valid.p'testing_file = 'data/test.p'with open(training_file, mode='rb') as f: train = pickle.load(f) #从“文件”中，读取字符串，将它们反序列化转换为Python的数据对象，可以正常像操作数据类型的这些方法来操作它们.with open(validation_file, mode='rb') as f: valid = pickle.load(f)with open(testing_file, mode='rb') as f: test = pickle.load(f) X_train, y_train = train['features'], train['labels']X_valid, y_valid = valid['features'], valid['labels']X_test, y_test = test['features'], test['labels'] 注意： train.p文件类似于一个文件夹的压缩包，取代了传统的大文件夹里面套小文件夹（标签），小文件夹里面存放若干图片读取的麻烦。 如果想要保存一些结果或者数据以方便后续使用，可以使用pickle模块。该模块接受几乎所有的python对象，并且将其转换成字符串表，该过程叫做封装。从字符串中重构该对象，称为拆封。这些字符串表示可以方便的存储和传输。由于上述特殊性，自然要用pickle模块来读取。 X_train是一个列表，里面存放所有的训练集图片。 y_train是一个列表，里面存放的均为数字，个数与X_train里面的图片数一致，数字的大小为图片对应的标签。 3.探索数据代码： 123456789101112###探索数据n_train = X_train.shape[0] #训练集照片总数n_validation = X_valid.shape[0] #验证集照片总数n_test = X_test.shape[0] #测试集照片总数image_shape = X_train.shape[1:] #训练集每张图片大小n_classes = len(set(y_train)) #标签数，即训练集所有照片被分成43类， #每一类为同一种交通标志，只有细微差异。print("Number of training examples =", n_train)print("Number of validation examples =", n_validation)print("Number of testing examples =", n_test)print("Image data shape =", image_shape)print("Number of classes =", n_classes) 打印： 12345Number of training examples = 34799Number of validation examples = 4410Number of testing examples = 12630Image data shape = (32, 32, 3)Number of classes = 43 注意： ​ 关于训练集、验证集、测试集。有个不恰当的比喻，深度学习好比高考。训练集为前期的输入，即用家庭作业巩固学习内容；验证集为阶段性测验，用来检验所学的成果并作出修正；测试集则是最后的高考，一局出结果。所以基本现象是，准确率 训练集&gt;验证集&gt;测试集。 4.数据预处理功能：规范化 代码： 1234###数据预处理#规范化X_train_normalised = util.normalise_images(X_train, X_train)X_valid_normalised = util.normalise_images(X_valid, X_train) util.py 12345678import numpy as npdef normalise_images(imgs, dist): std = np.std(dist) #计算每一个维度上数据的标准差 #std = 128 mean = np.mean(dist) #计算每一个维度上数据的均值 #mean = 128 return (imgs - mean) / std #在每一个维度上都减去该均值。 #然后在数据的每一维度上除以该维度上数据的标准差。 注意： 机器学习里有一句名言：数据和特征决定了机器学习的上限，而模型和算法的应用只是让我们逼近这个上限。这个说法形象且深刻的提出前期数据处理和特征分析的重要性。 ​ 数据预处理中，标准的第一步是数据归一化。虽然这里有一系列可行的方法，但是这一步通常是根据数据的具体情况而明确选择的。数据归一化常用的方法包含如下几种： 简单缩放 规范化(使数据集中所有特征都具有零均值和单位方差) 简单缩放 ​ 为了使得最终的数据向量落在 [0，1] 或 [ -1，1] 的区间内（根据数据情况而定）。 ​ 在处理自然图像时，我们获得的像素值在 [0，255] 区间中，常用的处理是将这些像素值 直接除以 255，使它们 缩放到 [0，1] 中。 规范化 ​ 规范化指的是（独立地）使得数据的每一个维度具有零均值和单位方差。这是归一化中最常见的方法并被广泛地使用（例如，在使用支持向量机（SVM）时，特征标准化常被建议用作预处理的一部分）。在实际应用中，特征标准化的具体做法是：首先计算每一个维度上数据的均值（使用全体数据计算），之后在每一个维度上都减去该均值。下一步便是在数据的每一维度上除以该维度上数据的标准差。 5.设计神经网络层功能： 深度学习分为深层神经网络、卷积神经网络、循环神经网络。其中深层神经网络（全连接层）最为常见，卷积神经网络适合用来进行图像处理，循环神经网络适合进行自然语言处理。 这里是基于经典卷积网络模型——LeNet-5模型。 我使用的是3层的卷积层加上3个全连接层，准确率达到0.96；之前还使用过一个全连接层，准确率达到0.48；还有2层的卷积层加上4个全连接层，准确率达到0.93。 5.1张量代码： 1234567inputs = tf.placeholder(tf.float32,shape = [None,32, 32, 3], name = 'inputs') #定义张量inputs #保存了三个属性：类型、维度、类型labels = tf.placeholder(tf.int32, shape = [None], name = 'labels') #定义张量labels，是预测结果one_hot_y = tf.one_hot(labels,n_classes) #独热标签dropout_placeholder_conv = tf.placeholder(tf.float32) #定义张量dropout_placeholder_convdropout_placeholder_fc = tf.placeholder(tf.float32) #定义张量dropout_placeholder_fc##前向传播 注意： Tensorflow中的张量和Numpy中的数组不同，Tensorflow计算的结果不是一个具体的数字，而是一个张量的结构。 独热编码一般是在有监督学习中对数据集进行标注时候使用的，指的是在分类问题中，将存在数据类别的那一类用X表示，不存在的用Y表示，这里的X常常是1， Y常常是0。 5.2 前向传播代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def mymodel(images,dropout_conv_pct,dropout_fc_pct): mu = 0 sigma = 0.1 prev_conv_layer = inputs input_img_dimensions = [32, 32, 3] conv_filter_size = 3 conv_depth_start = 32 conv_layers_count = 3 fc_output_dims = [120,84] output_classes = n_classes conv_input_depth = input_img_dimensions[-1] #3层卷积层、过滤器尺寸是3x3，过滤器深度是32，3层全连接层 print("[mymodel] Building neural network [conv layers=&#123;0&#125;, conv filter size=&#123;1&#125;, conv start depth=&#123;2&#125;, fc layers=&#123;3&#125;]".format( conv_layers_count, conv_filter_size, conv_depth_start, len(fc_output_dims)+1)) #用for循环实现3层卷积层 for i in range(0,conv_layers_count): conv_output_depth = conv_depth_start * (2 ** (i)) #3X3卷积层 conv_W = tf.Variable(tf.truncated_normal(shape=(conv_filter_size, conv_filter_size, conv_input_depth, conv_output_depth), mean = mu, stddev = sigma)) conv_b = tf.Variable(tf.zeros(conv_output_depth)) conv_output = tf.nn.conv2d(prev_conv_layer, conv_W, strides=[1, 1, 1, 1], padding='VALID', name="conv_&#123;0&#125;".format(i)) + conv_b conv_output = tf.nn.relu(conv_output, name="conv_&#123;0&#125;_relu".format(i)) #通过relu激活函数完成去线性化 # 2x2池化层 conv_output = tf.nn.max_pool(conv_output, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') # 应用dropout 防止过拟合，随机将部分节点的输出改为0 conv_output = tf.nn.dropout(conv_output, dropout_conv_pct) # 相应地设置循环变量 prev_conv_layer = conv_output conv_input_depth = conv_output_depth #扁平化(在保留第0轴的情况下对输入的张量进行Flatten) fc0 = flatten(prev_conv_layer) # 全连接层1,2 prev_layer = fc0 for output_dim in fc_output_dims: fcn_W = tf.Variable(tf.truncated_normal(shape=(prev_layer.get_shape().as_list()[-1], output_dim), mean = mu, stddev = sigma)) fcn_b = tf.Variable(tf.zeros(output_dim)) prev_layer = tf.nn.dropout(tf.nn.relu(tf.matmul(prev_layer, fcn_W) + fcn_b), dropout_fc_pct) #全连接层3 fc_final_W = tf.Variable(tf.truncated_normal(shape=(prev_layer.get_shape().as_list()[-1], output_classes), mean = mu, stddev = sigma)) fc_final_b = tf.Variable(tf.zeros(output_classes)) logits = tf.matmul(prev_layer, fc_final_W) + fc_final_b return logits 过程： ​ 这里我们的输入是32x32x3,第一层是3x3x32的卷积层，输出是30x30x32，然后跟着一个池化层，变成15X15X32； ​ 第二层是3x3x64的卷积层，输出是13x13x64，后面也是跟着一个池化层，变成6x6x64。 ​ 第三层是3x3x128的卷积层，输出是4x4x128，后面也是跟着一个池化层，变成2x2x64。 ​ 扁平化后2x2x64 = 512，所以全连接层设置为（512,120）、（120,84）、（84,43）。 打印： （可视化前向传播） 卷积层、池化层过程（数学角度） conv_output = tf.nn.conv2d(prev_conv_layer, conv_W, strides=[1, 1, 1, 1], padding=’VALID’, name=”conv_{0}”.format(i)) + conv_b ​ 其中有个参数 padding，在进行卷积运算，tensorflow提供两种SAME和VALID两种选择。其中”SAME“表示添加全0填充，“VALID“表示不添加。卷积层输出深度与卷积层过滤器深度一致。 （全零填充） （不全零填充，向上取整） 5.3 评估模型1234567891011121314151617181920212223242526272829##评估模型def evaluate_model(X_data, Y_data, batch_size): num_examples = len(X_data) total_accuracy = 0.0 total_loss = 0.0 sess = tf.get_default_session() for offset in range(0, num_examples, batch_size): batch_x, batch_y = X_data[offset:offset+batch_size], Y_data[offset:offset+batch_size] # 计算该512个数据样本的准确度和损失 accuracy = sess.run(accuracy_operation, feed_dict=&#123; dropout_placeholder_conv: 1.0, dropout_placeholder_fc: 1.0, inputs: batch_x, labels: batch_y &#125;) loss = sess.run(loss_operation, feed_dict=&#123; dropout_placeholder_conv: 1.0, dropout_placeholder_fc: 1.0, inputs: batch_x, labels: batch_y &#125;) # 整个数据集的期望 total_accuracy += (accuracy * len(batch_x)) total_loss += (loss * len(batch_x)) # 整个数据集的准确率和损失率 return (total_accuracy / num_examples, total_loss / num_examples) 6.训练神经网络功能： ​ 通过训练集和验证集训练神经网络，用来测试。因为训练的过程花费时间较长，为了让训练结果可以复用，需要将训练得到的神经网络模型持久化。这样在测试新的数据集，只需要先从持久化后模型文件中还原被保存的模型就可以了。 6.1定义全局变量代码： 123456789#定义一些全局变量epochs = 40learning_rate = 0.001batch_size = 512save_model_path = "datas/Traffice_sign_classifier"dropout_conv_keep_pct = 0.75dropout_fc_keep_pct = 0.5max_accuracy = 0PRINT_FREQ = 100 6.2反向传播代码： 123456789101112131415#前向传播logits = mymodel(inputs,dropout_placeholder_conv,dropout_placeholder_fc)#交叉熵来刻画损失函数（预测值和真实值） cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)#交叉熵平均值loss_operation = tf.reduce_mean(cross_entropy)#优化器optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)#通过传入loss_operation参数，使其得以更新并最小化training_operation =optimizer.minimize(loss_operation)#tf.equal函数判断两个张量的每一维是否相等，如果想等返回TRUE#tf.argmax函数来得到预测值和真实值对应的类别编号correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y,1))#首先将布尔型数据转换成实数型数据，然后计算平均值。这个平均值就是这个模型在这一组数据上的准确性。accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) 注意： ​ 神经网络模型的效果以及优化的目标是通过损失函数来定义的。 ​ 经典损失函数有处理分类问题的Softmax回归之后的交叉熵损失函数（cross_entropy = tf.nn.softmax_cross_entropy_with_logits(y,y_ )）（y为预测值，y_为真实值），还有处理回归问题的均方误差损失函数（mse = tf.resuce_mean（tf.square(y_) - y ））。 ​ 目前Tensorflow支持7种不同的优化器，比较常用的优化方法有三种：tf.train.GradientDescentOptimizer、tf.train.AdamOptimizer和tf.train.MomentumOptimizer。 6.3训练代码： 1234567891011121314151617181920212223242526272829#初始化会话并开始训练过程with tf.Session() as sess: sess.run(tf.global_variables_initializer()) #初始化所有变量 #40轮，每次选取512个样本进行训练。也就是训练结束一共进行了（num_examples/batch_size)*epochs次。 num_examples = len(X_train_normalised) print("Training mymodel [epochs=&#123;0&#125;, batch_size=&#123;1&#125;]...\n".format(epochs, batch_size)) #40轮训练 for i in range(epochs): X_train, Y_train = shuffle(X_train_normalised, y_train) #将序列的所有元素随机排序 #每一轮训练 for offset in range(0, num_examples, batch_size): end = offset + batch_size batch_x, batch_y = X_train[offset:end], Y_train[offset:end] sess.run(training_operation, feed_dict=&#123; inputs: batch_x, labels: batch_y, dropout_placeholder_conv:0.75, dropout_placeholder_fc:0.5, &#125;) training_accuracy, training_loss = evaluate_model(X_train_normalised, y_train, batch_size) validation_accuracy, validation_loss = evaluate_model(X_valid_normalised, y_valid, batch_size) #if i == 0 or (i+1) % PRINT_FREQ == 0: print("[&#123;0&#125;]\ttrain:loss=&#123;1:.4f&#125;, acc=&#123;2:.4f&#125; | val:loss=&#123;3:.4f&#125;, acc=&#123;4:.4f&#125;".format( i+1,training_loss, training_accuracy, validation_loss, validation_accuracy)) 6.4持久化代码： 123456789#tensorflow持久化 if validation_accuracy &gt; max_accuracy: max_acc = validation_accuracy #模型保存，先要创建一个Saver对象：如 saver=tf.train.Saver() #当然，如果你只想保存最后一代的模型，则只需要将max_to_keep设置为1即可 saver = tf.train.Saver(max_to_keep=1) save_path = saver.save(sess,save_model_path) #保存路径 model_file_name = "&#123;0&#125;.chkpt".format(save_model_path) print("Model &#123;0&#125; saved".format(model_file_name)) 打印： 7.测试神经网络功能：测试新的数据集，只需要先从持久化后模型文件中还原被保存的模型就可以了。可以省去训练模型耗费的大量时间。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128###1.读取数据training_file = 'datas/train.p'testing_file = 'datas/test.p' with open(testing_file, mode='rb') as f: test = pickle.load(f)with open(training_file, mode='rb') as f: train = pickle.load(f)X_train, y_train = train['features'], train['labels']X_test, y_test = test['features'], test['labels']n_classes = len(set(y_test))######2：数据预处理X_test_normalised = util.normalise_images(X_test, X_train)print(X_test_normalised.shape,y_test.shape)###3:设计神经网络层inputs = tf.placeholder(tf.float32,shape = [None,32, 32, 3], name = 'inputs')labels = tf.placeholder(tf.int32, shape = [None], name = 'labels')one_hot_y = tf.one_hot(labels,n_classes)dropout_placeholder_conv = tf.placeholder(tf.float32)dropout_placeholder_fc = tf.placeholder(tf.float32) def mymodel(images,dropout_conv_pct, dropout_fc_pct): mu = 0 sigma = 0.1 prev_conv_layer = inputs input_img_dimensions = [32, 32, 3] conv_filter_size = 3 conv_depth_start = 32 conv_layers_count = 3 fc_output_dims = [120,84] output_classes = n_classes conv_input_depth = input_img_dimensions[-1] print("[mymodel] Building neural network [conv layers=&#123;0&#125;, conv filter size=&#123;1&#125;, conv start depth=&#123;2&#125;, fc layers=&#123;3&#125;]".format( conv_layers_count, conv_filter_size, conv_depth_start, len(fc_output_dims))) for i in range(0,conv_layers_count): # 层深度呈指数增长 conv_output_depth = conv_depth_start * (2 ** (i)) conv_W = tf.Variable(tf.truncated_normal(shape=(conv_filter_size, conv_filter_size, conv_input_depth, conv_output_depth), mean = mu, stddev = sigma)) conv_b = tf.Variable(tf.zeros(conv_output_depth)) conv_output = tf.nn.conv2d(prev_conv_layer, conv_W, strides=[1, 1, 1, 1], padding='VALID', name="conv_&#123;0&#125;".format(i)) + conv_b conv_output = tf.nn.relu(conv_output, name="conv_&#123;0&#125;_relu".format(i)) print(conv_output) # 2x2池化层 conv_output = tf.nn.max_pool(conv_output, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID') print(conv_output) # 应用dropout 防止过拟合 conv_output = tf.nn.dropout(conv_output, dropout_conv_pct) print(conv_output) # 相应地设置循环变量 prev_conv_layer = conv_output conv_input_depth = conv_output_depth # 在保留第0轴的情况下对输入的张量进行Flatten(扁平化) fc0 = flatten(prev_conv_layer) print(fc0) # 全连接层1，2 prev_layer = fc0 for output_dim in fc_output_dims: fcn_W = tf.Variable(tf.truncated_normal(shape=(prev_layer.get_shape().as_list()[-1], output_dim), mean = mu, stddev = sigma)) fcn_b = tf.Variable(tf.zeros(output_dim)) prev_layer = tf.nn.dropout(tf.nn.relu(tf.matmul(prev_layer, fcn_W) + fcn_b), dropout_fc_pct) print(prev_layer) # 全连接层3 fc_final_W = tf.Variable(tf.truncated_normal(shape=(prev_layer.get_shape().as_list()[-1], output_classes), mean = mu, stddev = sigma)) fc_final_b = tf.Variable(tf.zeros(output_classes)) logits = tf.matmul(prev_layer, fc_final_W) + fc_final_b print(logits) return logits def evaluate_model(X_data, Y_data, batch_size): num_examples = len(X_data) total_accuracy = 0.0 sess = tf.get_default_session() for offset in range(0, num_examples, batch_size): batch_x, batch_y = X_data[offset:offset+batch_size], Y_data[offset:offset+batch_size] # 计算该批次的准确度和损失 accuracy = sess.run(accuracy_operation, feed_dict=&#123; dropout_placeholder_conv: 1.0, dropout_placeholder_fc: 1.0, inputs: batch_x, labels: batch_y &#125;) # 批量元素总数加权精度 total_accuracy += (accuracy * len(batch_x)) # 在整个数据集上生成真正的平均精度 return (total_accuracy / num_examples) learning_rate = 0.001batch_size = 512logits = mymodel(inputs,dropout_placeholder_conv,dropout_placeholder_fc)cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot_y, logits=logits)loss_operation = tf.reduce_mean(cross_entropy)optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)training_operation =optimizer.minimize(loss_operation)correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))###4.测试神经网络loaded_graph = tf.Graph() save_model_path = "datas/Traffice_sign_classifier"with tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver = tf.train.Saver() saver.restore(sess,save_model_path) #加载模型 test_accuracy = evaluate_model(X_test_normalised,y_test,batch_size) print("[mymodel - Test Set]\tacc=&#123;0:.4f&#125;".format(test_accuracy)) tf.reset_default_graph() #清除当前默认图中堆栈，重置默认图，实现模型参数的多次读取 注意： ​ 和训练.py文件基本一样，只是需要额外加一个加载模型的步骤。 打印： 后记 ​ 后续可以将训练好的模型应用于图像和视频流。]]></content>
      <categories>
        <category>无人驾驶环境感知</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>TensorFlow</tag>
        <tag>交通标志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于多态的职工管理系统]]></title>
    <url>%2F2019%2F01%2F16%2F%E8%81%8C%E5%B7%A5%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[1.管理系统需求职工管理系统可以用来管理公司内所有员工的信息。 本文主要利用C++来实现一个基于多态的职工管理系统。 公司中职工分为三类：普通员工、经理、老板、显示信息时，需要显示职工编号、职工姓名、职工岗位、以及职责 普通员工职责：完成经理交给的任务 经理职责：完成老板交给的任务，并下发任务给员工 老板职责：管理公司所有事物 管理系统中需要实现的功能如下： 退出管理程序：退出当前管理系统 增加职工信息：实现批量添加职工功能，将信息录入到文件中，职工信息为：职工编号、姓名、部门编号 显示职工信息：显示公司内所有职工的信息 删除离职职工：按照编号删除指定的职工 修改职工信息：按照编号修改职工个人信息 查找职工信息：按照职工的编号或者职工的姓名进行查找相关的人员信息 按照编号排序：按照职工编号，进行排序，排序规则由用户指定 清空所有文档：清空文件中记录的所有职工信息（清空前需要再次确认，防止误删） 系统界面效果图如下： 2.创建项目步骤： 创建新项目（基于多态的职工管理系统） 添加文件（职工管理系统） 3.创建管理类管理类负责的内容如下： 与用户的沟通菜单界面 对职工增删改查的操作 与文件的读写交互 3.1创建文件在头文件和源文件下分别创建workerManager.h和workerManager.cpp文件 3.2头文件实现在workerManager.h中设计管理类 代码如下： 1234567891011121314#pragma once //防止头文件重复包含#include &lt;iostream&gt; //包含输入输出流头文件using namespace std; //使用标准命名空间class WorkerManager&#123;public: //构造函数 WorkerManager(); //析构函数 ~WorkerManager()&#125;; 3.3源文件实现在workerManager.cpp中将构造和析构函数补全 12345678910#include"workerManager.h"WorkerManager::WorkerManager()&#123;&#125;WorkerManager::~WorkerManager()&#123;&#125; 至此职工管理类以创建完毕 4.菜单功能功能描述：与用户的沟通界面 4.1添加成员函数在管理类workerManager.h文件中添加成员函数void Show_Menu(); 12//展示菜单 void Show_Menu(); 4.2菜单功能实现在管理类workerManager.cpp中实现Show_Menu()函数 123456789101112131415void WorkerManager::Show_Menu()&#123; cout &lt;&lt; "********************************"&lt;&lt; endl; cout &lt;&lt; "**********欢迎使用职工管理系统！****"&lt;&lt; endl; cout &lt;&lt; "**********0.退出管理程序**********"&lt;&lt; endl; cout &lt;&lt; "**********1.增加职工信息**********"&lt;&lt; endl; cout &lt;&lt; "**********2.显示职工信息**********"&lt;&lt; endl; cout &lt;&lt; "**********3.删除离职职工**********"&lt;&lt; endl; cout &lt;&lt; "**********4.修改职工信息**********"&lt;&lt; endl; cout &lt;&lt; "**********5.查找职工信息**********"&lt;&lt; endl; cout &lt;&lt; "**********6.按照编号排序**********"&lt;&lt; endl; cout &lt;&lt; "**********7.清空所有文档**********"&lt;&lt; endl; cout &lt;&lt; "********************************"&lt;&lt; endl; cout &lt;&lt; endl;&#125; 4.3测试菜单功能在职工管理系统.cpp中测试菜单功能 代码： 12345678910111213141516#include &lt;iostream&gt;using namespace std;#include"workerManager.h"int main()&#123; //实例化管理者对象 WorkerManager wm; //调用展示菜单成员函数 wm.Show_Menu(); system("pause"); return 0;&#125; 5.退出功能5.1提供功能接口在main函数中提供分支选择，提供每个功能接口 代码： 12345678910111213141516171819202122232425262728293031323334353637383940int main()&#123; //实例化管理者对象 WorkerManager wm; int choice = 0; while (true) &#123; //调用展示菜单成员函数 wm.Show_Menu(); cout &lt;&lt; "请输入你的选择" &lt;&lt; endl; cin &gt;&gt; choice; switch (choice) &#123; case 0://退出系统 break; case 1://添加职工 break; case 2://显示职工 break; case 3://删除职工 break; case 4://修改职工 break; case 5://查找职工 break; case 6://排序职工 break; case 7://清空文件 break; default: system("cls"); break; &#125; &#125; system("pause"); return 0; &#125; 5.2实现退出功能在workerManager.h中提供退出系统的成员函数void_exitSystem(); 在workerManager.cpp提供具体的功能实现 123456void WorkerManager::exitSystem()&#123; cout &lt;&lt; "欢迎下次使用" &lt;&lt; endl; system("pause"); exit(0);&#125; 5.3测试功能在main函数分支0选项中,调用退出程序的接口 123case 0://退出系统 wm.exitSystem(); break; 6.创建职工类6.1创建职工抽象类职工的分类为：普通员工、经理、老板 将三种职工抽象到一个类（worker）中，利用多态管理不同员工种类 职工的属性为：职工编号、职工姓名、职工所在部门编号 职工的行为为：岗位职责信息描述，获取岗位名称 头文件文件夹下 创建文件worker.h文件并且添加如下代码： 123456789101112131415161718#pragma once //防止头文件重复包含#include &lt;iostream&gt; //包含输入输出流头文件#include&lt;string&gt;using namespace std; //使用标准命名空间//职工抽象基类class Worker&#123;public: //显示个人信息 virtual void showInfo() = 0; //获取岗位名称 virtual string getDepName() = 0; int m_ID;//职工编号 string m_Name;//职工姓名 int m_DeptId;//职工所在部门名称编号&#125;; 6.2创建普通员工类普通员工继承职工抽象类，并重写父类中纯虚函数 在头文件和源文件的文件夹下分别创建employee.h和employee.cpp文件 employee.h中代码如下： 1234567891011121314151617181920#pragma once //防止头文件重复包含#include &lt;iostream&gt; //包含输入输出流头文件#include"worker.h"using namespace std; //使用标准命名空间//员工类class Employee:public Worker //继承&#123;public: //构造函数 Employee(int id, string name, int dId); //显示个人信息 virtual void showInfo(); //获取岗位名称 virtual string getDepName();&#125;; employee.cpp中代码如下： 1234567891011121314151617181920#include "employee.h"Employee::Employee(int id, string name, int dId)&#123; this-&gt;m_ID = id; this-&gt;m_Name = name; this-&gt;m_DeptId = dId;&#125;void Employee::showInfo()&#123; cout &lt;&lt; "职工编号：" &lt;&lt; this-&gt;m_ID &lt;&lt; "\t职工姓名：" &lt;&lt; this-&gt;m_Name &lt;&lt; "\t岗位：" &lt;&lt; this-&gt;getDepName() &lt;&lt; "\t岗位职责：完成经理交给的任务" &lt;&lt; endl;&#125;string Employee::getDepName()&#123; return string("员工");&#125; 6.3创建经理类经理类继承职工抽象类，并重写父类中纯虚函数，和普通员工类似 在头文件和源文件的文件夹下分别创建manager.h和manager.cpp文件 manager.h中代码如下： 1234567891011121314151617181920#pragma once //防止头文件重复包含#include &lt;iostream&gt; //包含输入输出流头文件#include"worker.h"using namespace std; //使用标准命名空间//经理类class Manager :public Worker //继承&#123;public: //构造函数 Manager(int id, string name, int dId); //显示个人信息 virtual void showInfo(); //获取岗位名称 virtual string getDepName();&#125;; manager.cpp中代码如下： 1234567891011121314151617181920#include "manager.h"Manager::Manager(int id, string name, int dId)&#123; this-&gt;m_ID = id; this-&gt;m_Name = name; this-&gt;m_DeptId = dId;&#125;void Manager::showInfo()&#123; cout &lt;&lt; "职工编号：" &lt;&lt; this-&gt;m_ID &lt;&lt; "\t职工姓名：" &lt;&lt; this-&gt;m_Name &lt;&lt; "\t岗位：" &lt;&lt; this-&gt;getDepName() &lt;&lt; "\t岗位职责：完成老板交给的任务,并下发任务给员工" &lt;&lt; endl;&#125;string Manager::getDepName()&#123; return string("经理");&#125; 6.4创建老板类老板类继承职工抽象类，并重写父类中纯虚函数，和普通员工类似 在头文件和源文件的文件夹下分别创建boss.h和boss.cpp文件 boss.h中代码如下： 1234567891011121314151617181920#pragma once //防止头文件重复包含#include &lt;iostream&gt; //包含输入输出流头文件#include"worker.h"using namespace std; //使用标准命名空间//老板类class Boss :public Worker //继承&#123;public: //构造函数 Boss(int id, string name, int dId); //显示个人信息 virtual void showInfo(); //获取岗位名称 virtual string getDepName();&#125;; boss.cpp中代码如下： 1234567891011121314151617181920#include "boss.h"Boss::Boss(int id, string name, int dId)&#123; this-&gt;m_ID = id; this-&gt;m_Name = name; this-&gt;m_DeptId = dId;&#125;void Boss::showInfo()&#123; cout &lt;&lt; "职工编号：" &lt;&lt; this-&gt;m_ID &lt;&lt; "\t职工姓名：" &lt;&lt; this-&gt;m_Name &lt;&lt; "\t岗位：" &lt;&lt; this-&gt;getDepName() &lt;&lt; "\t岗位职责：管理公司所有事物" &lt;&lt; endl;&#125;string Boss::getDepName()&#123; return string("总裁");&#125; 6.5测试多态在职工管理系统.cpp中添加测试函数，并且运行能够产生多态 测试代码如下： 12345678910111213//测试代码 Worker * worker = NULL; worker = new Employee(1, "张三", 1); worker-&gt;showInfo(); delete worker; worker = new Manager(2, "李四", 2); worker-&gt;showInfo(); delete worker; worker = new Boss(3, "王五", 3); worker-&gt;showInfo(); delete worker; 7.添加职工功能描述：批量添加职工，并且保存到文件中 7.1功能分析用户在批量创建时，可能会创建不同种类的职工 如果将所有不同种类的员工都放入到一个数组中，可以将所有员工的指针维护到一个数组里 如果想在程序中维护做这个不定长度的数组，可以将数组创建到堆区。并利用Worker **的指针维护 7.2功能实现在WorkerManager.h头文件中添加成员属性 12345//记录文件中人数个数int m_EmpNum;//员工数组的指针Worker **m_EmpArray; 在WorkerManager.cpp构造函数中初始化属性 123456//初始化人数this-&gt;m_EmpNum = 0;//初始化数组指针this-&gt;m_EmpArray = NULL; 在WorkerManager.h中添加成员函数 12//增加职工void Add_Emp(); 在WorkerManager.cpp中实现该函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980void WorkerManager::Add_Emp()&#123; cout &lt;&lt; "请输入增加职工数量：" &lt;&lt; endl; int addNum = 0; cin &gt;&gt; addNum; if (addNum &gt; 0) &#123; //计算新空间大小 int newSize = this-&gt;m_EmpNum + addNum;//新空间人数 = 原来记录人数 + 新增人数 //开辟新空间 Worker ** newSpace = new Worker*[newSize]; //将原空间下内容存放到新空间下 if (this-&gt;m_EmpArray !=NULL) &#123; for (int i = 0; i &lt; this-&gt;m_EmpNum; i++) &#123; newSpace[i] = this-&gt;m_EmpArray[i]; &#125; &#125; //输入新数据 for (int i = 0; i &lt; addNum; i++) &#123; int id; string name; int dSelect; cout &lt;&lt; "请输入第" &lt;&lt; i + 1 &lt;&lt; "个新职工编号：" &lt;&lt; endl; cin &gt;&gt; id; cout &lt;&lt; "请输入第" &lt;&lt; i + 1 &lt;&lt; "个新职工姓名：" &lt;&lt; endl; cin &gt;&gt; name; cout &lt;&lt; "请选择该职工的岗位：" &lt;&lt; endl; cout &lt;&lt; "1.普通职工" &lt;&lt; endl; cout &lt;&lt; "2.经理" &lt;&lt; endl; cout &lt;&lt; "3.老板" &lt;&lt; endl; cin &gt;&gt; dSelect; Worker * worker = NULL; switch (dSelect) &#123; case 1: worker = new Employee(id, name, 1); break; case 2: worker = new Manager(id, name, 2); break; case 3: worker = new Boss(id, name, 3); break; default: break; &#125; newSpace[this-&gt;m_EmpNum + i] = worker; &#125; //释放原有空间 delete[] this-&gt;m_EmpArray; //更改新空间的指向 this-&gt;m_EmpArray = newSpace; //更新新的个数 this-&gt;m_EmpNum = newSize; //提示信息 cout &lt;&lt; "成功添加" &lt;&lt; addNum &lt;&lt; "名新职工" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "输出有误" &lt;&lt; endl; &#125; system("pause"); system("cls");&#125; 7.3测试添加123case 1://添加职工 wm.Add_Emp(); break; 8.文件交互-写文件功能描述：对文件进行读写 文件管理类中需要一个与文件进行交互的功能，对文件进行读写操作 8.1设定文件路径在workerManager.h中添加宏常量，并且包含头文件fstream 12#include &lt;fstream&gt;#define FILENAME "empFile.txt" 8.2成员函数声明在workerManager.h中添加成员函数void save() 12//保存文件void save(); 8.3保存文件功能实现12345678910111213void WorkerManager::save()&#123; ofstream ofs; ofs.open(FILENAME, ios::out); for (int i = 0; i &lt; this-&gt;m_EmpNum; i++) &#123; ofs &lt;&lt; this-&gt;m_EmpArray[i]-&gt;m_ID &lt;&lt; " " &lt;&lt; this-&gt;m_EmpArray[i]-&gt;m_Name &lt;&lt; " " &lt;&lt; this-&gt;m_EmpArray[i]-&gt;m_DeptId &lt;&lt; endl; &#125; ofs.close;&#125; 8.4保存文件功能测试在添加职工功能中添加成功后添加保存文件函数 9.文件交互-读文件功能描述：将文件内中的内容读取到程序中 虽然我们实现了添加职工后保存到文件的操作，但是每次开始运行程序，并没有将文件中数据读取到程序中 而我们的程序功能中还有清空文件的需求 因此构造函数初始化数据的情况分为三种 第一次使用，文本未创建 文件存在，但是数据被用户清空 文件存在，并且保存职工的所有信息 9.1文件未创建在workerManager.h中添加新的成员属性m_FileEmpty标志文件是否为空 12//标志文件是否为空bool m_FileIsEmpty; 修改WorkerManager.cpp中构造函数代码 123456789101112131415161718WorkerManager::WorkerManager()&#123; //1.文件不存在 ifstream ifs; ifs.open(FILENAME, ios::in);//读文件 if (!ifs.is_open()) &#123; cout &lt;&lt; "文件不存在" &lt;&lt; endl; //初始化人数 this-&gt;m_EmpNum = 0; //初始化数组指针 this-&gt;m_EmpArray = NULL; //初始化文件为空 this-&gt;m_FileIsEmpty = true; ifs.close(); return; &#125; 删除文件后，测试文件不存在时初始化数据功能 9.2文件存在且数据为空在workerManager.cpp中的构造函数追加代码： 12345678910111213141516//2.文件存在 数据为空 char ch; ifs &gt;&gt; ch; if (ifs.eof()) &#123; //文件为空 cout &lt;&lt; "文件为空！" &lt;&lt; endl; //初始化人数 this-&gt;m_EmpNum = 0; //初始化数组指针 this-&gt;m_EmpArray = NULL; //初始化文件为空 this-&gt;m_FileIsEmpty = true; ifs.close(); return; &#125; 9.3文件存在且保存职工数据9.3.1获取记录的职工人数在workerManager.h中添加成员函数int get_EmpNum(); 12//统计人数int get_EmpNum(); workerManager.cpp中实现 12345678910111213141516171819int WorkerManager::get_EmpNum()&#123; ifstream ifs; ifs.open(FILENAME, ios::in); int id; string name; int dID; int num = 0; while (ifs &gt;&gt; id &amp;&amp; ifs &gt;&gt; name &amp;&amp; ifs &gt;&gt; dID) &#123; //记录人数 num++; &#125; ifs.close(); return num;&#125; 在workerManager.cpp中继续追加代码： 1234//3.当文件存在，并且记录数据int num = this-&gt;get_EmpNum();cout &lt;&lt; "职工人数为：" &lt;&lt; num &lt;&lt; endl;this-&gt;m_EmpNum = num; 9.3.2初始化数组 初始化数组 根据职工的数据以及职工数据，初始化workManager中的Worker**m_EmpArray指针 在workerManager.h中添加成员函数 void init_Emp() 12//初始化员工void init_Emp(); 在workerManager.cpp中实现 12345678910111213141516171819202122232425262728293031void WorkerManager::init_Emp()&#123; ifstream ifs; ifs.open(FILENAME, ios::in); int id; string name; int dId; int index = 0; while (ifs &gt;&gt; id &amp;&amp; ifs &gt;&gt; name &amp;&amp; ifs &gt;&gt; dId) &#123; Worker * worker = NULL; //根据不同的部门Id创建不同对象 if (dId == 1) &#123; worker = new Employee(id, name, dId); &#125; else if (dId == 2) &#123; worker = new Manager(id, name, dId); &#125; else &#123; worker = new Boss(id, name, dId); &#125; //存放在数组中 this-&gt;m_EmpArray[index] = worker; index++; &#125;&#125; 10.显示职工功能描述：显示当前所有职工信息 10.1 显示职工函数声明在workerManager.h中添加成员函数void Show_Emp(); 12//显示职工void Show_Emp(); 10.2显示职工函数实现在workerManager.cpp中实现成员函数void Show_Emp(); 1234567891011121314151617void WorkerManager::Show_Emp()&#123; if (this-&gt;m_FileIsEmpty) &#123; cout &lt;&lt; "文件不存在或者记录为空" &lt;&lt; endl; &#125; else &#123; for (int i = 0; i &lt; m_EmpNum; i++) &#123; //利用多态调用接口 this-&gt;m_EmpArray[i]-&gt;showInfo; &#125; &#125; system("pause"); system("cls");&#125; 10.3显示职工函数测试测试1：文件不存在或者为空情况 测试2：文件存在且有记录情况 11.删除职工功能描述：按照职工的编号进行删除职工操作 11.1删除职工函数声明在workerManager.h中添加成员函数添加void Del_Emp()； 11.2职工是否存在函数声明很多功能都需要用到根据职工是否存在来进行操作如：删除职工、修改职工、查找职工 因此添加该公告函数，以便后续调用 在workerManager.h中添加成员函数int IsExist(int id); 11.3职工是否存在函数实现在workerManager.cpp中实现成员函数int IsExist(int id); 12345678910111213141516int WorkerManager::IsExist(int id)&#123; int index = -1; for (int i = 0; i &lt; this-&gt;m_EmpNum; i++) &#123; if (this-&gt;m_EmpArray[i]-&gt;m_ID == id) &#123; //找到职工 index = i; break; &#125; &#125; return index;&#125; 11.4删除职工函数实现在workerManager.cpp中实现成员函数void Del_Emp()； 1234567891011121314151617181920212223242526272829303132333435363738//删除职工void WorkerManager::Del_Emp()&#123; if (this-&gt;m_FileIsEmpty) &#123; cout &lt;&lt; "文件不存在或记录为空！" &lt;&lt; endl; &#125; else &#123; //按照职工编号删除 cout &lt;&lt; "请输入想要删除职工编号：" &lt;&lt; endl; int id = 0; cin &gt;&gt; id; int index = this-&gt;IsExist(id); if (index != -1)//说明职工存在，并且要删除掉index位置上的职工 &#123; for (int i = index; i &lt; this-&gt;m_EmpNum - 1; i++) &#123; //数据前移 this-&gt;m_EmpArray[i] = this-&gt;m_EmpNum[i + 1]; &#125; this-&gt;m_EmpNum--;//更新数组中记录人员个数 //数据同步更新到文件中 this-&gt;save(); cout &lt;&lt; "删除成功" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "删除失败，未找到该职工" &lt;&lt; endl; &#125; &#125; system("pause"); system("cls");&#125; 11.5测试删除职工测试1：删除不存在职工情况 测试2：文件存在职工情况 12.修改职工12.1修改职工函数声明在workerManager.h中添加成员函数void Mod_Emp(); 12.2修改职工函数实现在workerManager.cpp中实现成员函数void Mod_Emp(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//修改职工void WorkerManager::Mod_Emp()&#123; if (this-&gt;m_FileIsEmpty) &#123; cout &lt;&lt; "文件不存在或者记录为空" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "请输入修改职工编号：" &lt;&lt; endl; int id; cin &gt;&gt; id; int ret = this-&gt;IsExist(id); if (ret != -1) &#123; //查找到编号的职工 delete this-&gt;m_EmpArray[ret]; int newId = 0; string newName = ""; int dSelect = 0; cout &lt;&lt; "查到：" &lt;&lt; id &lt;&lt; "号职工，请输入新职工号：" &lt;&lt; endl; cin &gt;&gt; newId; cout &lt;&lt; "请输入新姓名：" &lt;&lt; endl; cin &gt;&gt; newName; cout &lt;&lt; "请输入岗位：" &lt;&lt; endl; cout &lt;&lt; "1.普通职工" &lt;&lt; endl; cout &lt;&lt; "2.经理" &lt;&lt; endl; cout &lt;&lt; "3.老板" &lt;&lt; endl; cin &gt;&gt; dSelect; Worker * worker = NULL; switch (dSelect) &#123; case 1: worker = new Employee(newId, newName, dSelect); break; case 2: worker = new Manager(newId, newName, dSelect); break; case 3: worker = new Boss(newId, newName, dSelect); break; default: break; &#125; //更新数据 到数组中 this-&gt;m_EmpArray[ret] = worker; //提示信息 cout &lt;&lt; "修改成功" &lt;&lt; endl; //保存到文件中 this-&gt;save(); &#125; else &#123; cout &lt;&lt; "修改失败，查无此人" &lt;&lt; endl; &#125; &#125; //清屏 system("pause"); system("cls");&#125; 13.查找职工功能描述：提供两种职工查找方式，一种按照职工编号，一种按照职工姓名 13.1查找职工函数声明在workerManager.h中添加成员函数void Find_Emp(); 13.2查找职工函数实现在workerManager.h中实现成员函数void Find_Emp(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//查找职工void WorkerManager::Find_Emp()&#123; if (this-&gt;m_FileIsEmpty) &#123; cout &lt;&lt; "文件不存在或者记录为空" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "请输入查找的方式：" &lt;&lt; endl; cout &lt;&lt; "1.按职工编号查找" &lt;&lt; endl; cout &lt;&lt; "2.按职工姓名查找" &lt;&lt; endl; int select = 0; cin &gt;&gt; select; if (select ==1 ) &#123; //按照编号查 int id; cout &lt;&lt; "请输入查找的职工编号：" &lt;&lt; endl; cin &gt;&gt; id; int ret = IsExist(id); if (ret != -1) &#123; cout &lt;&lt; "查找成功！该职工信息如下：" &lt;&lt; endl; this-&gt;m_EmpArray[ret]-&gt;showInfo(); &#125; else &#123; cout &lt;&lt; "查找失败，查无此人" &lt;&lt; endl; &#125; &#125; else if(select == 2) &#123; //按照姓名查 string name; cout &lt;&lt; "请输入查找的姓名：" &lt;&lt; endl; cin &gt;&gt; name; // 加入判断是否查到的标志 bool flag = false; //默认未找到职工 for (int i = 0; i &lt; m_EmpNum; i++) &#123; if (this-&gt;m_EmpArray[i]-&gt;m_Name == name) &#123; cout &lt;&lt; "查找成功！职工编号为：" &lt;&lt; this-&gt;m_EmpArray[i]-&gt;m_ID &lt;&lt;"号职工信息如下："&lt;&lt; endl; flag = true; this-&gt;m_EmpArray[i]-&gt;showInfo(); &#125; &#125; if (flag = false) &#123; cout &lt;&lt; "查找失败，查无此人" &lt;&lt; endl; &#125; &#125; else &#123; cout &lt;&lt; "输入选项有误！" &lt;&lt; endl; &#125; &#125; //按任意键清屏 system("pause"); system("cls");&#125; 13.3测试查找职工测试1：按照职工编号查找-查找不存在职工 测试2：按照职工编号查找-查找存在职工 测试3：按照职工姓名查找-查找不存在职工 测试4：按照职工姓名查找-查找存在职工（如果出现重名，也一并显示，在文件中可以添加重名职工） 14.排序功能描述：按照职工编号进行排序 14.1排序函数声明 在workerManager.h中添加成员函数void Sort_Emp(); 14.2排序函数实现 在workerManager.cpp中实现成员函数void Sort_Emp(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//排序职工void WorkerManager::Sort_Emp()&#123; if (this-&gt;m_FileIsEmpty) &#123; cout &lt;&lt; "文件不存在或者记录为空" &lt;&lt; endl; //清屏 system("pause"); system("cls"); &#125; else &#123; cout &lt;&lt; "请选择排序的方式：" &lt;&lt; endl; cout &lt;&lt; "1.按职工编号进行升序排" &lt;&lt; endl; cout &lt;&lt; "2.按职工编号进行降序排" &lt;&lt; endl; int select = 0; cin &gt;&gt; select; for (int i = 0; i &lt; m_EmpNum; i++) &#123; int minOrMax = i;//声明最小值或者最大值下标 for (int j = i + 1; j &lt; this-&gt;m_EmpNum; j++) &#123; if (select == 1)//升序 &#123; if (this-&gt;m_EmpArray[minOrMax]-&gt;m_ID &gt; this-&gt;m_EmpArray[j]-&gt;m_ID) &#123; minOrMax = j; &#125; &#125; else //降序 &#123; if (this-&gt;m_EmpArray[minOrMax]-&gt;m_ID &lt; this-&gt;m_EmpArray[j]-&gt;m_ID) &#123; minOrMax = j; &#125; &#125; &#125; //判断一开始认定 最小值或最大值 是不是 计算的 最小值或最大值，如果不是 交换数据 if (i != minOrMax ) &#123; Worker * temp = this-&gt;m_EmpArray[i]; this-&gt;m_EmpArray[i] = this-&gt;m_EmpArray[minOrMax]; this-&gt;m_EmpArray[minOrMax] = temp; &#125; &#125; cout &lt;&lt; "排序成功！排序后的结果为：" &lt;&lt; endl; this-&gt;save(); this-&gt;Show_Emp();&#125; 15.清空文件15.1清空函数声明 在workerManager.h中添加成员函数void Clean_File(); 15.2清空函数实现 在workerManager.cpp中实现成员函数void Clean_File(); 12345678910111213141516171819202122232425262728293031323334353637//清空文件void WorkerManager::Clean_File()&#123; cout &lt;&lt; "确定清空？" &lt;&lt; endl; cout &lt;&lt; "1.确定" &lt;&lt; endl; cout &lt;&lt; "2.返回" &lt;&lt; endl; int select = 0; cin &gt;&gt; select; if (select == 1) &#123; //清空文件 ofstream ofs(FILENAME, ios::trunc); ofs.close(); if (this-&gt;m_EmpArray != NULL) &#123; for (int i = 0; i &lt; this-&gt;m_EmpNum; i++) &#123; //删除堆区的每个职工对象 delete this-&gt;m_EmpArray[i]; this-&gt;m_EmpArray[i] = NULL; //删除堆区数组指针 delete[] this-&gt;m_EmpArray; this-&gt;m_EmpArray = NULL; this-&gt;m_EmpNum = 0; this-&gt;m_FileIsEmpty = true; &#125; cout &lt;&lt; "清除成功！" &lt;&lt; endl; &#125; //清屏 system("pause"); system("cls"); &#125;&#125; 以上。]]></content>
      <categories>
        <category>小项目</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通讯录管理系统]]></title>
    <url>%2F2019%2F01%2F04%2F%E9%80%9A%E8%AE%AF%E5%BD%95%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[1.系统需求通讯录是一个可以记录亲人、好友信息的工具。 本博客主要是利用C++来实现一个通讯录管理系统。 系统需要实现的功能如下： 添加联系人：向通讯录中添加新人，信息包括（姓名、性别、年龄、联系电话、家庭住址）最多记录10000人 显示联系人：显示通讯录中所有联系人信息 删除联系人：按照姓名进行删除指定联系人 查找联系人：按照姓名查看指定联系人信息 修改联系人：按照姓名重新修改指定联系人 清空联系人：清空通讯录中所有信息 退出通讯录：退出当前使用的通讯录 2.菜单功能功能描述：用户选择功能的界面 效果图如下： 步骤： 封装函数void showMenu（）显示该界面 在main函数中调用封装好的函数 代码： 12345678910111213//显示菜单界面void showMenu()&#123; cout &lt;&lt; "**************************" &lt;&lt; endl; cout &lt;&lt; "***** 1.添加联系人 *****" &lt;&lt; endl; cout &lt;&lt; "***** 2.显示联系人 ***** " &lt;&lt; endl; cout &lt;&lt; "***** 3.删除联系人 ***** " &lt;&lt; endl; cout &lt;&lt; "***** 4.查找联系人 ***** " &lt;&lt; endl; cout &lt;&lt; "***** 5.修改联系人 ***** " &lt;&lt; endl; cout &lt;&lt; "***** 6.清空联系人 ***** " &lt;&lt; endl; cout &lt;&lt; "***** 7.退出通讯录 ***** " &lt;&lt; endl; cout &lt;&lt; "**************************" &lt;&lt; endl;&#125; 注意：为了使界面更加的美观整洁，可以适当添加 *。 3.退出功能功能描述：退出通讯录系统 思路：根据用户不同的选择，进入不同的功能，可以选择switch分支结构，将整个架构进行搭建 当用户选择7的时候，执行退出，选择其他先不做操作，也不会退出程序 12345678910111213141516171819202122232425262728293031323334int main()&#123; int select = 0; //创建用户选择输入的变量 while (true) &#123; //菜单调用 showMenu(); cin &gt;&gt; select; switch (select) &#123; case 1: //添加联系人 break; case 2: //显示联系人 break; case 3: //删除联系人 break; case 4: //查找联系人 break; case 5: //修改联系人 break; case 6: //清空联系人 break; case 7: //退出通讯录 cout &lt;&lt; "欢迎下次使用" &lt;&lt; endl; system("pause"); return 0; break; default: break; &#125; &#125; 注意：按7退出switch分支结构，但仍在while循环中，即会显示菜单。 5.添加联系人功能描述：实现添加联系人功能联系人上限为1000人，联系人信息包括姓名、性别、年龄、联系电话、家庭住址。 步骤： 设计联系人结构体 设计通讯录结构体 main函数中创建通讯录 封装添加联系人函数 测试添加联系人功能 5.1设计联系人结构体联系人信息包括：姓名、性别、年龄、联系电话、家庭住址 代码： 12345678910#define MAX 1000//设计联系人结构体struct Person&#123; string m_Name; int m_Sex; int m_Age; string m_Phone; string m_Addr;&#125;; 5.2设计通讯录结构体在通讯录结构体中，维护一个容量为1000的存放联系人的数组，并记录当前通讯录中联系人数量 123456789#define MAX 1000//设计通讯录结构体struct Addressbooks&#123; //通讯录中保存的联系人数组 struct Person personArray[MAX]; //通讯录中当前记录联系人个数 int m_Size;&#125;; 5.3 main函数中创建通讯录1234//创建通讯录结构体变量Addressbooks abs;//初始化通讯录中当前人员个数abs.m_Size = 0; 5.4 封装添加联系人函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//1.添加联系人void addPerson(Addressbooks * abs)&#123; if (abs -&gt;m_Size ==MAX) &#123; cout &lt;&lt; "通讯录已满，无法添加！" &lt;&lt; endl; return; &#125; else &#123; //添加具体联系人 //姓名 string name; cout &lt;&lt; "请输入姓名：" &lt;&lt; endl; cin &gt;&gt; name; abs-&gt;personArray[abs-&gt;m_Size].m_Name = name; //性别 cout &lt;&lt; "请输入性别：" &lt;&lt; endl; cout &lt;&lt; "1 --男 " &lt;&lt; endl; cout &lt;&lt; "2 --女 " &lt;&lt; endl; int sex = 0; while (true) &#123; cin &gt;&gt; sex; if (sex == 1 || sex == 2) &#123; abs-&gt;personArray[abs-&gt;m_Size].m_Sex = sex; break; &#125; cout &lt;&lt; "输入有误，请重新输入" &lt;&lt; endl; &#125; //年龄 cout &lt;&lt; "请输入年龄：" &lt;&lt; endl; int age = 0; cin &gt;&gt; age; abs-&gt;personArray[abs-&gt;m_Size].m_Age = age; //电话 cout &lt;&lt; "请输入电话：" &lt;&lt; endl; string phone; cin &gt;&gt; phone; abs-&gt;personArray[abs-&gt;m_Size].m_Phone = phone; //住址 cout &lt;&lt; "请输入家庭住址：" &lt;&lt; endl; string address; cin &gt;&gt; address; abs-&gt;personArray[abs-&gt;m_Size].m_Addr = address; //更新通讯录人数 abs-&gt;m_Size++; cout &lt;&lt; "添加成功" &lt;&lt; endl; system("pause");//请按任意键继续 system("cls");//清屏操作 &#125;&#125; 5.5测试添加联系人功能123case 1: //添加联系人 addPerson(&amp;abs); //利用地址传递，可以修饰实参 break; 注意： 判断通讯录人数有没有满 使用清屏操作，只显示菜单，继续使用通讯录。 6.显示联系人功能描述：显示通讯录中已有联系人的信息 步骤： 封装显示联系人函数 测试显示联系人功能 6.1 封装显示联系人函数思路：判断如果当前通讯录中没有人员，就提示记录为空，人数大于0，遍历显示通讯录中信息 代码： 123456789101112131415161718192021//2.显示所有联系人void showPerson(Addressbooks * abs)&#123; if (abs-&gt;m_Size == 0) &#123; cout &lt;&lt; "当前记录为空" &lt;&lt; endl; &#125; else &#123; for (int i = 0; i &lt; abs-&gt;m_Size; i++) &#123; cout &lt;&lt; "姓名：" &lt;&lt; abs-&gt;personArray[i].m_Name &lt;&lt; " "; cout &lt;&lt; "性别：" &lt;&lt; (abs-&gt;personArray[i].m_Sex == 1 ?"男":"女") &lt;&lt; " "; cout &lt;&lt; "年龄：" &lt;&lt; abs-&gt;personArray[i].m_Age &lt;&lt; " "; cout &lt;&lt; "联系人方式：" &lt;&lt; abs-&gt;personArray[i].m_Phone &lt;&lt; " "; cout &lt;&lt; "家庭住址：" &lt;&lt; abs-&gt;personArray[i].m_Addr &lt;&lt; endl; &#125; &#125; system("pause");//请按任意键继续 system("cls");//清屏操作&#125; 6.2 测试显示联系人功能123case 2: //显示联系人 showPerson(&amp;abs); break; 7.删除联系人功能描述：按照姓名进行删除指定联系人 步骤： 封装检测联系人是否存在 封装删除联系人函数 测试删除联系人函数 7.1 封装检测联系人是否存在思路：删除联系人前，我们需要先判断用户输入的联系人是否存在，如果存在删除，不存在提示用户没有要删除的联系人 因此我们可以把检测联系人是否存在封装成一个函数中，如果存在，返回联系人在通讯录中的位置，不存在返回-1 代码： 1234567891011121314//检测联系人函数//检测联系人是否存在，如果存在，返回联系人所在数组中的具体位置，不存在返回-1//参数1 通讯录 参数2 对比姓名int isExist(Addressbooks * abs, string name)&#123; for (int i = 0; i &lt; abs-&gt;m_Size; i++) &#123; if (abs-&gt;personArray[i].m_Name == name ) &#123; return i; &#125; &#125; return -1;&#125; 7.2 封装删除联系人函数123456789101112131415161718192021222324252627//3.删除指定联系人void deletePerson(Addressbooks * abs)&#123; cout &lt;&lt; "请输入您要删除的联系人" &lt;&lt; endl; string name; cin &gt;&gt; name; int ret = isExist(abs,name); if (ret != -1) &#123; for (int i = ret; i &lt; abs-&gt;m_Size; i++) &#123; abs-&gt;personArray[i] = abs-&gt;personArray[i + 1]; &#125; abs-&gt;m_Size--; cout &lt;&lt; "删除成功" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "查无此人" &lt;&lt; endl; &#125; system("pause");//请按任意键继续 system("cls");//清屏操作&#125; 7.3 测试删除联系人函数123case 3: //删除联系人 deletePerson(&amp;abs); break; 注意： 删除联系人思路为下标为2位置的数据，将下标为2位置后的数据做向前移动，并让通讯录中记录人员的个数做-1的操作。 8.查找联系人功能描述：按照姓名查看指定联系人信息 步骤： 封装查找联系人函数 测试查找联系人函数 8.1封装查找联系人函数思路：判断用户指定的联系人是否存在，如果存在显示信息，不存在则提示查无此人 代码： 123456789101112131415161718192021222324void searchPerson(Addressbooks * abs)&#123; cout &lt;&lt; "请输入您要查找的联系人" &lt;&lt; endl; string name; cin &gt;&gt; name; int ret = isExist(abs, name); if (ret != -1) &#123; cout &lt;&lt; "姓名：" &lt;&lt; abs-&gt;personArray[ret].m_Name &lt;&lt; " "; cout &lt;&lt; "性别：" &lt;&lt; (abs-&gt;personArray[ret].m_Sex == 1 ? "男" : "女") &lt;&lt; " "; cout &lt;&lt; "年龄：" &lt;&lt; abs-&gt;personArray[ret].m_Age &lt;&lt; " "; cout &lt;&lt; "联系人方式：" &lt;&lt; abs-&gt;personArray[ret].m_Phone &lt;&lt; " "; cout &lt;&lt; "家庭住址：" &lt;&lt; abs-&gt;personArray[ret].m_Addr &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "查无此人" &lt;&lt; endl; &#125; system("pause");//请按任意键继续 system("cls");//清屏操作&#125; 8.2测试查找联系人函数123case 4: //查找联系人 searchPerson(&amp;abs); break; 9.修改联系人功能描述：按照姓名重新修改指定联系人 步骤： 封装修改联系人函数 测试修改联系人函数 9.1封装修改联系人函数思路：查找用户输入的联系人，如果查找成功进行修改操作，查找失败提示查无此人 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//5.修改联系人void modifyPerson(Addressbooks * abs)&#123; cout &lt;&lt; "请输入您要修改的联系人" &lt;&lt; endl; string name; cin &gt;&gt; name; int ret = isExist(abs, name); if (ret != -1) &#123; //姓名 string name; cout &lt;&lt; "请输入姓名：" &lt;&lt; endl; cin &gt;&gt; name; abs-&gt;personArray[ret].m_Name = name; //性别 cout &lt;&lt; "请输入性别：" &lt;&lt; endl; cout &lt;&lt; "1 --男 " &lt;&lt; endl; cout &lt;&lt; "2 --女 " &lt;&lt; endl; int sex = 0; while (true) &#123; cin &gt;&gt; sex; if (sex == 1 || sex == 2) &#123; abs-&gt;personArray[ret].m_Sex = sex; break; &#125; cout &lt;&lt; "输入有误，请重新输入" &lt;&lt; endl; &#125; //年龄 cout &lt;&lt; "请输入年龄：" &lt;&lt; endl; int age = 0; cin &gt;&gt; age; abs-&gt;personArray[ret].m_Age = age; //电话 cout &lt;&lt; "请输入电话：" &lt;&lt; endl; string phone; cin &gt;&gt; phone; abs-&gt;personArray[ret].m_Phone = phone; //住址 cout &lt;&lt; "请输入家庭住址：" &lt;&lt; endl; string address; cin &gt;&gt; address; abs-&gt;personArray[ret].m_Addr = address; &#125; else &#123; cout &lt;&lt; "查无此人" &lt;&lt; endl; &#125; system("pause");//请按任意键继续 system("cls");//清屏操作&#125; 9.2 测试修改联系人函数123case 5: //修改联系人 modifyPerson(&amp;abs); break; 注意：这里基本操作和添加联系人类似 10.清空联系人功能描述：清空通讯录中所有信息 步骤： 封装清空联系人联系人函数 测试清空联系人联系人函数 10.1封装清空联系人联系人函数思路：只要将通讯录中记录的联系人数量重置为0，做逻辑清空即可 代码： 12345678//6.清空通讯录void cleanPerson(Addressbooks * abs)&#123; abs-&gt;m_Size = 0; //将当期记录联系人数重置为0；做逻辑清空操作 cout &lt;&lt; "通讯录已清空" &lt;&lt; endl; system("pause");//请按任意键继续 system("cls");//清屏操作&#125; 10.1封装清空联系人联系人函数123case 6: //清空联系人 cleanPerson(&amp;abs); break; 以上。]]></content>
      <categories>
        <category>小项目</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
